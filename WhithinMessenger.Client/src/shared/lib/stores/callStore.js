import { create } from 'zustand';
import { devtools } from 'zustand/middleware';
import { voiceCallApi } from '../../../entities/voice-call/api/voiceCallApi';
import { NoiseSuppressionManager } from '../utils/noiseSuppression';
import { audioNotificationManager } from '../utils/audioNotifications';
import { VoiceActivityDetector } from '../utils/voiceActivityDetector';
import { RoomEvent, Track } from 'livekit-client';
import { userApi } from '../../../entities/user/api/userApi';
import { MEDIA_BASE_URL } from '../constants/apiEndpoints';

// ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ banner Ğ¿ÑƒÑ‚Ñ‘Ğ¼ Ğº Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸Ğ»Ğ¸ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼
const isBannerImage = (banner) => {
  if (!banner) return false;
  
  // Ğ•ÑĞ»Ğ¸ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ #, ÑÑ‚Ğ¾ Ñ†Ğ²ĞµÑ‚
  if (banner.startsWith('#')) return false;
  
  // Ğ•ÑĞ»Ğ¸ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, ÑÑ‚Ğ¾ Ğ¿ÑƒÑ‚ÑŒ Ğº Ñ„Ğ°Ğ¹Ğ»Ñƒ
  const imageExtensions = ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg', '.bmp'];
  const lowerBanner = banner.toLowerCase();
  if (imageExtensions.some(ext => lowerBanner.includes(ext))) return true;
  
  // Ğ•ÑĞ»Ğ¸ Ğ½Ğ°Ñ‡Ğ¸Ğ½Ğ°ĞµÑ‚ÑÑ Ñ http://, https://, /uploads/, /api/, ÑÑ‚Ğ¾ Ğ¿ÑƒÑ‚ÑŒ
  if (banner.startsWith('http://') || 
      banner.startsWith('https://') || 
      banner.startsWith('/uploads/') || 
      banner.startsWith('/api/') ||
      banner.startsWith('uploads/')) {
    return true;
  }
  
  // Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ½Ñ‹Ğ¹ hex-Ñ†Ğ²ĞµÑ‚ (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, #5865f2), ÑÑ‚Ğ¾ Ñ†Ğ²ĞµÑ‚
  const hexColorPattern = /^#[0-9A-Fa-f]{6}$/;
  if (hexColorPattern.test(banner)) return false;
  
  // ĞŸĞ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼, ĞµÑĞ»Ğ¸ Ğ½Ğµ Ğ¿Ğ¾Ñ…Ğ¾Ğ¶Ğµ Ğ½Ğ° Ğ¿ÑƒÑ‚ÑŒ
  return false;
};

// ICE ÑĞµÑ€Ğ²ĞµÑ€Ñ‹ Ğ´Ğ»Ñ WebRTC
const ICE_SERVERS = [
  { urls: ['stun:185.119.59.23:3478'] },
  { urls: ['stun:stun.l.google.com:19302'] },
  { urls: ['stun:stun1.l.google.com:19302'] },
  {
    urls: ['turn:185.119.59.23:3478?transport=udp'],
    username: 'test',
    credential: 'test123'
  },
  {
    urls: ['turn:185.119.59.23:3478?transport=tcp'],
    username: 'test',
    credential: 'test123'
  }
];

export const useCallStore = create(
  devtools(
    (set, get) => ({
      // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ·Ğ²Ğ¾Ğ½ĞºĞ°
      isConnected: false,
      isInCall: false,
      currentRoomId: null,
      currentUserId: null,
      currentUserName: null,
      currentCall: null,
      
      // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
      participants: [],
      peerIdToUserIdMap: new Map(),
      processedProducers: new Set(),
      
      // Ğ£Ñ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¸ Ğ²ÑĞµÑ… Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ² (Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ²)
      // Map: channelId -> [{ userId, userName, avatar, avatarColor, isMuted }]
      voiceChannelParticipants: new Map(),
      
      // ĞÑ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ (Ğ¸Ğ·Ğ±ĞµĞ³Ğ°ĞµĞ¼ Ğ¿ĞµÑ€ĞµÑ€ĞµĞ½Ğ´ĞµÑ€Ğ° Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑ€Ğ°Ğ½Ğ°)
      participantMuteStates: new Map(), // userId -> isMuted
      participantAudioStates: new Map(), // userId -> isAudioEnabled
      participantGlobalAudioStates: new Map(), // userId -> isGlobalAudioMuted
      participantVideoStates: new Map(), // userId -> isVideoEnabled
      participantSpeakingStates: new Map(), // userId -> isSpeaking (Voice Activity Detection)
      
      // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ (Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¸Ğ· localStorage)
      isMuted: (() => {
        try {
          const saved = localStorage.getItem('micMuted');
          const value = saved ? JSON.parse(saved) : false;
          console.log('ğŸ¤ Loaded mic state from localStorage:', value);
          return value;
        } catch {
          return false;
        }
      })(),
      isAudioEnabled: (() => {
        try {
          const saved = localStorage.getItem('audioMuted');
          const value = saved ? !JSON.parse(saved) : true; // Ğ¸Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ: audioMuted=true Ğ·Ğ½Ğ°Ñ‡Ğ¸Ñ‚ isAudioEnabled=false
          console.log('ğŸ”Š Loaded audio state from localStorage:', value);
          return value;
        } catch {
          return true;
        }
      })(),
      isGlobalAudioMuted: (() => {
        try {
          const saved = localStorage.getItem('audioMuted');
          const value = saved ? JSON.parse(saved) : false;
          console.log('ğŸ§ Loaded global audio muted state from localStorage:', value);
          return value;
        } catch {
          return false;
        }
      })(),
      isNoiseSuppressed: false,
      noiseSuppressionMode: 'rnnoise',
      userVolumes: new Map(),
      userMutedStates: new Map(),
      showVolumeSliders: new Map(),
      
      // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
      error: null,
      audioBlocked: false,
      
      // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑ€Ğ°Ğ½Ğ°
      isScreenSharing: false,
      screenShareStream: null,
      remoteScreenShares: new Map(),
      
  // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
  isVideoEnabled: false,
  cameraStream: null, // ĞÑ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ´Ğ»Ñ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
  videoProducer: null, // Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑ€Ğ°Ğ½Ğ° Ğ¾Ñ‚ Ğ´Ñ€ÑƒĞ³Ğ¸Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹ (producerId -> data)
      
      // WebRTC ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ñ (Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑÑ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾)
      device: null,
      sendTransport: null,
      recvTransport: null,
      producers: new Map(),
      consumers: new Map(),
      localStream: null,
      noiseSuppressionManager: null,
      audioContext: null,
      gainNodes: new Map(),
      audioElements: new Map(),
      previousVolumes: new Map(),
      voiceActivityDetectors: new Map(), // userId -> VoiceActivityDetector
      localVoiceActivityDetector: null, // VAD Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
      
      // Ğ¤Ğ»Ğ°Ğ³Ğ¸ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
      connecting: false,
      
      // Actions
      setError: (error) => set({ error }),
      clearError: () => set({ error: null }),
      
      setAudioBlocked: (blocked) => set({ audioBlocked: blocked }),
      
      // Voice Activity Detection (VAD) Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸
      updateSpeakingState: (userId, isSpeaking) => {
        const state = get();
        // ĞĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ ĞµÑĞ»Ğ¸ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½ Ğ·Ğ°Ğ¼ÑŒÑÑ‡ĞµĞ½ (Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ)
        if (userId === state.currentUserId && state.isMuted && isSpeaking) {
          return; // Ğ˜Ğ³Ğ½Ğ¾Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ speaking=true ĞºĞ¾Ğ³Ğ´Ğ° Ğ¼ÑŒÑÑ‚ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½
        }
        
        set((prevState) => {
          const newSpeakingStates = new Map(prevState.participantSpeakingStates);
          newSpeakingStates.set(userId, isSpeaking);
          return { participantSpeakingStates: newSpeakingStates };
        });
      },
      
      // Ğ¡Ğ±Ñ€Ğ¾Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
      resetSpeakingState: (userId) => {
        set((state) => {
          const newSpeakingStates = new Map(state.participantSpeakingStates);
          newSpeakingStates.set(userId, false);
          return { participantSpeakingStates: newSpeakingStates };
        });
      },
      
      // Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°Ğ¼Ğ¸ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ñ… ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ² (Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ²)
      setVoiceChannelParticipants: (channelId, participants) => {
        set((state) => {
          const newMap = new Map(state.voiceChannelParticipants);
          if (participants && participants.length > 0) {
            newMap.set(channelId, participants);
          } else {
            newMap.delete(channelId);
          }
          return { voiceChannelParticipants: newMap };
        });
      },
      
      addVoiceChannelParticipant: (channelId, participant) => {
        set((state) => {
          const newMap = new Map(state.voiceChannelParticipants);
          const currentParticipants = newMap.get(channelId) || [];
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ½ĞµÑ‚ Ğ»Ğ¸ ÑƒĞ¶Ğµ Ñ‚Ğ°ĞºĞ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° (Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¸ odUserId Ğ¸ userId)
          const participantId = participant.odUserId || participant.userId;
          if (!currentParticipants.some(p => (p.odUserId === participantId) || (p.userId === participantId))) {
            newMap.set(channelId, [...currentParticipants, participant]);
          }
          return { voiceChannelParticipants: newMap };
        });
      },
      
      removeVoiceChannelParticipant: (channelId, odUserId) => {
        set((state) => {
          const newMap = new Map(state.voiceChannelParticipants);
          const currentParticipants = newMap.get(channelId) || [];
          const filteredParticipants = currentParticipants.filter(p => p.odUserId !== odUserId && p.userId !== odUserId);
          if (filteredParticipants.length > 0) {
            newMap.set(channelId, filteredParticipants);
          } else {
            newMap.delete(channelId);
          }
          return { voiceChannelParticipants: newMap };
        });
      },
      
      updateVoiceChannelParticipant: (channelId, odUserId, updates) => {
        set((state) => {
          const newMap = new Map(state.voiceChannelParticipants);
          const currentParticipants = newMap.get(channelId) || [];
          const updatedParticipants = currentParticipants.map(p => 
            (p.odUserId === odUserId || p.userId === odUserId) ? { ...p, ...updates } : p
          );
          newMap.set(channelId, updatedParticipants);
          return { voiceChannelParticipants: newMap };
        });
      },
      
      clearVoiceChannelParticipants: (channelId) => {
        set((state) => {
          const newMap = new Map(state.voiceChannelParticipants);
          newMap.delete(channelId);
          return { voiceChannelParticipants: newMap };
        });
      },
      
      // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ VAD Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
      initializeLocalVAD: async (stream, audioContext) => {
        const state = get();
        const userId = state.currentUserId;
        
        if (!userId || !stream) return;
        
        // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€
        if (state.localVoiceActivityDetector) {
          state.localVoiceActivityDetector.cleanup();
        }
        
        const detector = new VoiceActivityDetector({
          audioContext,
          threshold: 30, // Ğ£Ğ²ĞµĞ»Ğ¸Ñ‡ĞµĞ½ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ´Ğ»Ñ Ğ¼ĞµĞ½ÑŒÑˆĞµĞ¹ Ñ‡ÑƒĞ²ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸
          holdTime: 350,
          onSpeakingChange: (isSpeaking) => {
            // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ÑŒÑÑ‚Ğ° Ğ¿ĞµÑ€ĞµĞ´ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼
            const currentState = get();
            if (currentState.isMuted) {
              // Ğ•ÑĞ»Ğ¸ Ğ·Ğ°Ğ¼ÑŒÑÑ‡ĞµĞ½, Ğ²ÑĞµĞ³Ğ´Ğ° ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ speaking = false
              if (currentState.participantSpeakingStates.get(userId)) {
                get().resetSpeakingState(userId);
              }
              // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ speaking: false Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€
              if (voiceCallApi.socket) {
                voiceCallApi.socket.emit('speaking', { speaking: false });
              }
              return;
            }
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
            get().updateSpeakingState(userId, isSpeaking);
            
            // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ Ñ€Ğ°ÑÑÑ‹Ğ»ĞºĞ¸ Ğ²ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°Ğ¼
            if (voiceCallApi.socket) {
              voiceCallApi.socket.emit('speaking', { speaking: isSpeaking });
              console.log('[VAD] Sent speaking state to server:', isSpeaking);
            }
          }
        });
        
        await detector.start(stream, audioContext);
        set({ localVoiceActivityDetector: detector });
        console.log('[VAD] Initialized local voice activity detector for user:', userId);
      },
      
      // Ğ¡Ğ»ÑƒÑˆĞ°Ñ‚ÑŒ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ñ‹Ñ… ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
      initializeSpeakingStateListener: () => {
        if (!voiceCallApi.socket) {
          console.warn('[VAD] Socket not available for speaking state listener');
          return;
        }
        
        // Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
        voiceCallApi.socket.off('speakingStateChanged');
        
        // Ğ¡Ğ»ÑƒÑˆĞ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ°
        voiceCallApi.socket.on('speakingStateChanged', ({ peerId, userId: eventUserId, speaking }) => {
          console.log('[VAD] Received speaking state from server:', { peerId, userId: eventUserId, speaking });
          
          // ĞĞµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ğ¾Ğ½ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµÑ‚ÑÑ Ñ‡ĞµÑ€ĞµĞ· Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ VAD)
          const currentState = get();
          if (peerId === voiceCallApi.socket?.id) {
            return;
          }
          
          // ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ userId
          // 1. Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ userId Ğ¸Ğ· ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ñ ĞµÑĞ»Ğ¸ Ğ¾Ğ½ ĞµÑÑ‚ÑŒ
          let userId = eventUserId;
          
          // 2. Ğ•ÑĞ»Ğ¸ Ğ½ĞµÑ‚, Ğ¸Ñ‰ĞµĞ¼ Ğ² peerIdToUserIdMap
          if (!userId) {
            userId = currentState.peerIdToUserIdMap?.get(peerId);
          }
          
          // 3. Ğ•ÑĞ»Ğ¸ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸, Ğ¸Ñ‰ĞµĞ¼ ÑÑ€ĞµĞ´Ğ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ğ¿Ğ¾ peerId
          if (!userId) {
            const participant = currentState.participants.find(p => 
              p.peerId === peerId || p.socketId === peerId
            );
            if (participant) {
              userId = participant.userId || participant.id;
            }
          }
          
          // 4. Ğ•ÑĞ»Ğ¸ Ğ²ÑÑ‘ ĞµÑ‰Ñ‘ Ğ½Ğµ Ğ½Ğ°ÑˆĞ»Ğ¸ userId, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ peerId
          if (!userId) {
            console.warn('[VAD] Could not find userId for peerId, participants:', 
              currentState.participants.map(p => ({ peerId: p.peerId, userId: p.userId }))
            );
            userId = peerId;
          }
          
          // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ Ğ±ÑƒĞ´ÑƒÑ‰Ğ¸Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
          if (userId && userId !== peerId && !currentState.peerIdToUserIdMap?.has(peerId)) {
            const newMap = new Map(currentState.peerIdToUserIdMap);
            newMap.set(peerId, userId);
            set({ peerIdToUserIdMap: newMap });
            console.log('[VAD] Added mapping peerId -> userId:', { peerId, userId });
          }
          
          console.log('[VAD] Using userId:', { peerId, userId, speaking });
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ÑŒÑÑ‚Ğ° ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°
          const participantIsMuted = currentState.participantMuteStates?.get(userId);
          if (participantIsMuted && speaking) {
            console.log('[VAD] Skipping speaking state for muted participant:', userId);
            return; // ĞĞµ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ½Ğ´Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ĞµÑĞ»Ğ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸Ğº Ğ·Ğ°Ğ¼ÑŒÑÑ‡ĞµĞ½
          }
          
          get().updateSpeakingState(userId, speaking);
        });
        
        console.log('[VAD] Speaking state listener initialized');
      },
      
      // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ VAD Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° (ÑƒÑÑ‚Ğ°Ñ€ĞµĞ»Ğ¾ - Ñ‚ĞµĞ¿ĞµÑ€ÑŒ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ°)
      initializeRemoteVAD: async (userId, stream, audioContext) => {
        // Ğ‘Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ VAD Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ñ‹Ñ… ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
        // Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ñ‡ĞµÑ€ĞµĞ· speakingStateChanged ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ
        console.log('[VAD] Remote VAD skipped for user (using server state):', userId);
      },
      
      // ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° VAD Ğ´Ğ»Ñ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°
      cleanupVAD: (userId) => {
        const state = get();
        
        const detector = state.voiceActivityDetectors.get(userId);
        if (detector) {
          detector.cleanup();
          const newDetectors = new Map(state.voiceActivityDetectors);
          newDetectors.delete(userId);
          
          const newSpeakingStates = new Map(state.participantSpeakingStates);
          newSpeakingStates.delete(userId);
          
          set({ 
            voiceActivityDetectors: newDetectors,
            participantSpeakingStates: newSpeakingStates
          });
          console.log('[VAD] Cleaned up voice activity detector for user:', userId);
        }
      },
      
      // ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ²ÑĞµÑ… VAD
      cleanupAllVAD: () => {
        const state = get();
        
        if (state.localVoiceActivityDetector) {
          state.localVoiceActivityDetector.cleanup();
        }
        
        for (const detector of state.voiceActivityDetectors.values()) {
          detector.cleanup();
        }
        
        set({
          localVoiceActivityDetector: null,
          voiceActivityDetectors: new Map(),
          participantSpeakingStates: new Map()
        });
        console.log('[VAD] Cleaned up all voice activity detectors');
      },
      
      // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ·Ğ²Ğ¾Ğ½ĞºĞ°
      initializeCall: async (userId, userName) => {
        const state = get();
        if (state.connecting) {
          console.log('Connection already in progress, skipping');
          return;
        }
        
        set({ connecting: true, currentUserId: userId, currentUserName: userName });
        
        try {
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ·Ğ²ÑƒĞºĞ¾Ğ²Ğ¾Ğ¹ Ğ¼ĞµĞ½ĞµĞ´Ğ¶ĞµÑ€
          await audioNotificationManager.initialize();
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸
          voiceCallApi.off('peerJoined');
          voiceCallApi.off('peerLeft');
          voiceCallApi.off('peerMuteStateChanged');
          voiceCallApi.off('peerAudioStateChanged');
          voiceCallApi.off('newProducer');
          voiceCallApi.off('producerClosed');
          voiceCallApi.off('globalAudioStateChanged');
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ socket Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸
          if (voiceCallApi.socket) {
            voiceCallApi.socket.off('globalAudioState');
          }
          
          await voiceCallApi.connect(userId, userName);
          
          // Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹
          voiceCallApi.on('peerJoined', async (peerData) => {
            console.log('Peer joined:', peerData);
            const socketId = peerData.peerId || peerData.id;
            const peerUserId = peerData.userId;
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ peerId -> userId
            if (socketId && peerUserId) {
              const newMap = new Map(get().peerIdToUserIdMap);
              newMap.set(socketId, peerUserId);
              set({ peerIdToUserIdMap: newMap });
              console.log('[VAD] peerJoined: Added mapping', { socketId, userId: peerUserId });
            } else {
              console.warn('[VAD] peerJoined: Missing socketId or userId', { socketId, userId: peerUserId, peerData });
            }
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ participantGlobalAudioStates Ğ´Ğ»Ñ Ñ€ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ UI
            set((state) => {
              const newGlobalAudioStates = new Map(state.participantGlobalAudioStates);
              if (peerData.isGlobalAudioMuted !== undefined) {
                newGlobalAudioStates.set(peerData.userId, peerData.isGlobalAudioMuted);
                console.log('Updated participantGlobalAudioStates for user:', peerData.userId, 'isGlobalAudioMuted:', peerData.isGlobalAudioMuted);
              }
              return { participantGlobalAudioStates: newGlobalAudioStates };
            });
            
            // Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°
            let profileData = null;
            try {
              const profile = await userApi.getProfile(peerData.userId);
              if (profile) {
                // ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ banner Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ»Ğ¸ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼
                const bannerIsImage = isBannerImage(profile.banner);
                const bannerValue = profile.banner 
                  ? (bannerIsImage ? `${MEDIA_BASE_URL}${profile.banner}` : profile.banner)
                  : null;
                
                profileData = {
                  avatar: profile.avatar ? `${MEDIA_BASE_URL}${profile.avatar}` : null,
                  avatarColor: profile.avatarColor || '#5865f2',
                  banner: bannerValue
                };
                console.log('ğŸ“¸ Loaded profile for participant:', peerData.userId, profileData);
              }
            } catch (error) {
              console.warn('Failed to load profile for participant:', peerData.userId, error);
            }
            
            set((state) => ({
              participants: [...state.participants.filter(p => p.userId !== peerData.userId), {
                userId: peerData.userId,
                peerId: socketId,
                name: peerData.name,
                isMuted: peerData.isMuted || false,
                isAudioEnabled: peerData.isAudioEnabled !== undefined ? peerData.isAudioEnabled : true,
                isGlobalAudioMuted: peerData.isGlobalAudioMuted || false, // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
                isSpeaking: false,
                avatar: profileData?.avatar || null,
                avatarColor: profileData?.avatarColor || '#5865f2',
                banner: profileData?.banner || null
              }]
            }));

            // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ² voiceChannelParticipants
            const currentRoomId = get().currentRoomId;
            if (currentRoomId) {
              get().addVoiceChannelParticipant(currentRoomId, {
                odUserId: peerData.userId,
                userName: peerData.name || peerData.userName,
                isMuted: peerData.isMuted || false,
                isGlobalAudioMuted: peerData.isGlobalAudioMuted || false,
                isAudioDisabled: peerData.isGlobalAudioMuted || false,
                isDeafened: peerData.isGlobalAudioMuted || false,
                avatar: profileData?.avatar || null,
                avatarColor: profileData?.avatarColor || '#5865f2'
              });
              console.log('ğŸ“¢ Added peer to voice channel participants:', peerData.userId);
            }

            // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            audioNotificationManager.playUserJoinedSound().catch(error => {
              console.warn('Failed to play user joined sound:', error);
            });
          });

          voiceCallApi.on('peerLeft', (peerData) => {
            console.log('Peer left:', peerData);
            const socketId = peerData.peerId || peerData.id;
            const userId = peerData.userId || get().peerIdToUserIdMap.get(socketId);
            
            if (userId) {
              // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ audio element
              const audioElement = get().audioElements.get(userId);
              if (audioElement) {
                audioElement.pause();
                audioElement.srcObject = null;
                if (audioElement.parentNode) {
                  audioElement.parentNode.removeChild(audioElement);
                }
              }
              
              // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ gain node
              const gainNode = get().gainNodes.get(userId);
              if (gainNode) {
                try {
                  gainNode.disconnect();
                } catch (e) {
                  console.warn('Error disconnecting gain node:', e);
                }
              }
              
              // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Voice Activity Detector Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
              get().cleanupVAD(userId);
              
              // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ
              set((state) => {
                const newUserVolumes = new Map(state.userVolumes);
                const newUserMutedStates = new Map(state.userMutedStates);
                const newShowVolumeSliders = new Map(state.showVolumeSliders);
                const newGainNodes = new Map(state.gainNodes);
                const newAudioElements = new Map(state.audioElements);
                const newPreviousVolumes = new Map(state.previousVolumes);
                const newPeerIdToUserIdMap = new Map(state.peerIdToUserIdMap);
                
                newUserVolumes.delete(userId);
                newUserMutedStates.delete(userId);
                newShowVolumeSliders.delete(userId);
                newGainNodes.delete(userId);
                newAudioElements.delete(userId);
                newPreviousVolumes.delete(userId);
                newPeerIdToUserIdMap.delete(socketId);
                
                return {
                  userVolumes: newUserVolumes,
                  userMutedStates: newUserMutedStates,
                  showVolumeSliders: newShowVolumeSliders,
                  gainNodes: newGainNodes,
                  audioElements: newAudioElements,
                  previousVolumes: newPreviousVolumes,
                  peerIdToUserIdMap: newPeerIdToUserIdMap,
                  participants: state.participants.filter(p => p.userId !== userId)
                };
              });
              
              // Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ğ¸Ğ· voiceChannelParticipants
              const currentRoomId = get().currentRoomId;
              if (currentRoomId) {
                get().removeVoiceChannelParticipant(currentRoomId, userId);
                console.log('ğŸ“¢ Removed peer from voice channel participants:', userId);
              }
            }

            // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
            audioNotificationManager.playUserLeftSound().catch(error => {
              console.warn('Failed to play user left sound:', error);
            });
          });

          voiceCallApi.on('peerMuteStateChanged', ({ peerId, isMuted }) => {
            const userId = get().peerIdToUserIdMap.get(peerId) || peerId;
            const mutedState = Boolean(isMuted);
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ÑŒÑÑ‚Ğ°, Ğ½Ğµ Ğ²ĞµÑÑŒ Ğ¼Ğ°ÑÑĞ¸Ğ² ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
            set((state) => {
              const newMuteStates = new Map(state.participantMuteStates);
              newMuteStates.set(userId, mutedState);
              return { participantMuteStates: newMuteStates };
            });
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
            set((state) => ({
              participants: state.participants.map(p => 
                p.userId === userId ? { ...p, isMuted: mutedState, isSpeaking: mutedState ? false : p.isSpeaking } : p
              )
            }));
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ voiceChannelParticipants
            const currentRoomId = get().currentRoomId;
            if (currentRoomId) {
              get().updateVoiceChannelParticipant(currentRoomId, userId, { isMuted: mutedState });
            }
          });

          voiceCallApi.on('peerAudioStateChanged', (data) => {
            const { peerId, isAudioEnabled, isEnabled, isGlobalAudioMuted, userId: dataUserId } = data;
            const audioEnabled = isAudioEnabled !== undefined ? isAudioEnabled : isEnabled;
            const userId = dataUserId || get().peerIdToUserIdMap.get(peerId) || peerId;
            
            console.log('peerAudioStateChanged received:', { peerId, userId, isAudioEnabled: audioEnabled, isGlobalAudioMuted });
            console.log('Full data received:', data);
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
            set((state) => {
              const newAudioStates = new Map(state.participantAudioStates);
              newAudioStates.set(userId, Boolean(audioEnabled));
              
              const newGlobalAudioStates = new Map(state.participantGlobalAudioStates);
              if (isGlobalAudioMuted !== undefined) {
                newGlobalAudioStates.set(userId, isGlobalAudioMuted);
              }
              
              return {
                participantAudioStates: newAudioStates,
                participantGlobalAudioStates: newGlobalAudioStates
              };
            });
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
            set((state) => ({
              participants: state.participants.map(p => {
                if (p.userId === userId) {
                  const updated = { ...p, isAudioEnabled: Boolean(audioEnabled) };
                  // Ğ•ÑĞ»Ğ¸ ÑĞµÑ€Ğ²ĞµÑ€ Ğ¿ĞµÑ€ĞµĞ´Ğ°ĞµÑ‚ isGlobalAudioMuted, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞµĞ³Ğ¾
                  if (isGlobalAudioMuted !== undefined) {
                    updated.isGlobalAudioMuted = isGlobalAudioMuted;
                    console.log('Updated participant with global audio state:', updated);
                  } else {
                    console.log('isGlobalAudioMuted not provided by server, keeping existing state');
                    // ĞĞµ Ğ¸Ğ·Ğ¼ĞµĞ½ÑĞµĞ¼ isGlobalAudioMuted, ĞµÑĞ»Ğ¸ ÑĞµÑ€Ğ²ĞµÑ€ ĞµĞ³Ğ¾ Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ´Ğ°ĞµÑ‚
                  }
                  return updated;
                }
                return p;
              })
            }));
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ voiceChannelParticipants
            const currentRoomId = get().currentRoomId;
            if (currentRoomId && isGlobalAudioMuted !== undefined) {
              get().updateVoiceChannelParticipant(currentRoomId, userId, {
                isGlobalAudioMuted,
                isAudioDisabled: isGlobalAudioMuted,
                isDeafened: isGlobalAudioMuted
              });
            }
          });

          // Handle TrackSubscribed events from LiveKit (for callStore)
          voiceCallApi.on('trackSubscribed', async ({ track, publication, participant, userId, mediaType }) => {
            console.log('ğŸ”Š callStore: Track subscribed event received:', { 
              trackSid: track?.sid, 
              kind: track?.kind, 
              userId, 
              mediaType,
              hasMediaStreamTrack: !!track?.mediaStreamTrack
            });
            
            // Check if track has mediaStreamTrack
            if (!track.mediaStreamTrack) {
              console.error('callStore: Track has no mediaStreamTrack!', track);
              return;
            }
            
            const state = get();
            const targetUserId = userId || participant.identity;
            
            // Handle VIDEO tracks (screen share and camera)
            if (track.kind === 'video') {
              console.log('ğŸ¥ callStore: Video track subscribed:', { mediaType, targetUserId });
              
              // Skip own video tracks
              if (targetUserId === state.currentUserId) {
                console.log('ğŸ¥ callStore: Skipping own video track');
                return;
              }
              
              const videoStream = new MediaStream([track.mediaStreamTrack]);
              
              if (mediaType === 'screen') {
                // Screen share video
                console.log('ğŸ–¥ï¸ callStore: Remote screen share detected for user:', targetUserId);
                
                const newRemoteScreenShares = new Map(state.remoteScreenShares);
                newRemoteScreenShares.set(track.sid, {
                  stream: videoStream,
                  producerId: track.sid,
                  userId: targetUserId,
                  userName: participant.name || targetUserId,
                  socketId: participant.identity
                });
                
                set({ remoteScreenShares: newRemoteScreenShares });
                console.log('ğŸ–¥ï¸ callStore: Remote screen share added, total:', newRemoteScreenShares.size);
              } else if (mediaType === 'camera') {
                // Camera video
                console.log('ğŸ“¹ callStore: Remote camera video detected for user:', targetUserId);
                
                // Update participant video states
                set((state) => {
                  const newVideoStates = new Map(state.participantVideoStates);
                  newVideoStates.set(targetUserId, true);
                  return { participantVideoStates: newVideoStates };
                });
                
                // Update participant with video stream
                set((state) => ({
                  participants: state.participants.map(p => 
                    p.userId === targetUserId 
                      ? { ...p, isVideoEnabled: true, videoStream: videoStream }
                      : p
                  )
                }));
                
                console.log('ğŸ“¹ callStore: Participant video updated for:', targetUserId);
              }
              
              return; // Exit after handling video
            }
            
            // Handle AUDIO tracks
            // Skip screen share audio (handled separately if needed)
            if (mediaType === 'screen') {
              console.log('ğŸ”Š callStore: Screen share audio track, creating audio element');
              // Create audio element for screen share audio
              const audioElement = document.createElement('audio');
              audioElement.srcObject = new MediaStream([track.mediaStreamTrack]);
              audioElement.autoplay = true;
              audioElement.volume = 1.0;
              audioElement.playsInline = true;
              audioElement.style.display = 'none';
              document.body.appendChild(audioElement);
              
              try {
                await audioElement.play();
                console.log('ğŸ”Š callStore: Screen share audio playback started');
              } catch (error) {
                console.warn('ğŸ”Š callStore: Screen share audio autoplay blocked:', error);
              }
              return;
            }
            
            // Check if we already have an audio element for this user
            if (state.audioElements.has(targetUserId)) {
              console.log('ğŸ”Š callStore: Audio element already exists for user:', targetUserId, 'updating...');
              const existingElement = state.audioElements.get(targetUserId);
              existingElement.srcObject = new MediaStream([track.mediaStreamTrack]);
              try {
                await existingElement.play();
                console.log('ğŸ”Š callStore: Updated audio element playback started');
              } catch (error) {
                console.warn('ğŸ”Š callStore: Failed to play updated audio element:', error);
              }
              return;
            }
            
            // Initialize AudioContext if needed
            let audioContext = state.audioContext;
            if (!audioContext || audioContext.state === 'closed') {
              audioContext = new (window.AudioContext || window.webkitAudioContext)({
                sampleRate: 48000,
                latencyHint: 'interactive'
              });
              set({ audioContext });
            }
            
            // Resume audio context if suspended
            if (audioContext.state === 'suspended') {
              await audioContext.resume();
            }
            
            // Create audio element
            const audioElement = document.createElement('audio');
            const mediaStream = new MediaStream([track.mediaStreamTrack]);
            audioElement.srcObject = mediaStream;
            audioElement.autoplay = true;
            audioElement.playsInline = true;
            audioElement.controls = false;
            audioElement.style.display = 'none';
            document.body.appendChild(audioElement);
            console.log('ğŸ”Š callStore: Created audio element for user:', targetUserId);
            
            // Create Web Audio API chain: source -> gain
            const source = audioContext.createMediaStreamSource(mediaStream);
            const gainNode = audioContext.createGain();
            
            // Set initial volume
            const initialVolume = state.userVolumes.get(targetUserId) || 100;
            const isMuted = state.userMutedStates.get(targetUserId) || false;
            const audioVolume = state.isGlobalAudioMuted ? 0 : (isMuted ? 0 : (initialVolume / 100.0));
            audioElement.volume = audioVolume;
            gainNode.gain.value = audioVolume;
            
            // Connect source -> gain (not to destination to avoid double playback)
            source.connect(gainNode);
            
            // Save references
            set((state) => {
              const newGainNodes = new Map(state.gainNodes);
              const newAudioElements = new Map(state.audioElements);
              const newUserVolumes = new Map(state.userVolumes);
              
              newGainNodes.set(targetUserId, gainNode);
              newAudioElements.set(targetUserId, audioElement);
              if (!newUserVolumes.has(targetUserId)) {
                newUserVolumes.set(targetUserId, 100);
              }
              
              return {
                gainNodes: newGainNodes,
                audioElements: newAudioElements,
                userVolumes: newUserVolumes
              };
            });
            
            // Try to play audio element
            try {
              await audioElement.play();
              console.log('ğŸ”Šâœ… callStore: Audio playback started for peer:', targetUserId);
              set({ audioBlocked: false });
            } catch (error) {
              console.warn('ğŸ”Šâš ï¸ callStore: Auto-play blocked, user interaction required:', error);
              set({ audioBlocked: true });
              setTimeout(async () => {
                try {
                  await audioElement.play();
                  console.log('ğŸ”Šâœ… callStore: Audio playback started after delay');
                  set({ audioBlocked: false });
                } catch (err) {
                  console.error('ğŸ”ŠâŒ callStore: Audio playback still blocked:', err);
                }
              }, 1000);
            }
          });

          // Handle video state changes (camera muted/unmuted)
          voiceCallApi.on('peerVideoStateChanged', ({ peerId, isVideoEnabled, userId, track, mediaType }) => {
            console.log('ğŸ¥ callStore: peerVideoStateChanged received:', { peerId, isVideoEnabled, userId, mediaType });
            
            const state = get();
            const targetUserId = userId || peerId;
            
            // Skip own video state changes
            if (targetUserId === state.currentUserId) {
              console.log('ğŸ¥ callStore: Skipping own video state change');
              return;
            }
            
            if (mediaType === 'camera') {
              // Update participant video states
              set((state) => {
                const newVideoStates = new Map(state.participantVideoStates);
                newVideoStates.set(targetUserId, isVideoEnabled);
                return { participantVideoStates: newVideoStates };
              });
              
              if (isVideoEnabled && track && track.mediaStreamTrack) {
                // Video enabled - update with new stream
                const videoStream = new MediaStream([track.mediaStreamTrack]);
                set((state) => ({
                  participants: state.participants.map(p => 
                    p.userId === targetUserId 
                      ? { ...p, isVideoEnabled: true, videoStream: videoStream }
                      : p
                  )
                }));
                console.log('ğŸ“¹ callStore: Participant video enabled for:', targetUserId);
              } else {
                // Video disabled - clear stream
                set((state) => ({
                  participants: state.participants.map(p => 
                    p.userId === targetUserId 
                      ? { ...p, isVideoEnabled: false, videoStream: null }
                      : p
                  )
                }));
                console.log('ğŸ“¹ callStore: Participant video disabled for:', targetUserId);
              }
            } else if (mediaType === 'screen') {
              // Handle screen share mute/unmute
              if (!isVideoEnabled) {
                // Screen share stopped - remove from remoteScreenShares
                console.log('ğŸ–¥ï¸ callStore: Screen share stopped for user:', targetUserId);
                set((state) => {
                  const newRemoteScreenShares = new Map(state.remoteScreenShares);
                  // Remove all screen shares from this user
                  for (const [key, value] of newRemoteScreenShares.entries()) {
                    if (value.userId === targetUserId) {
                      newRemoteScreenShares.delete(key);
                    }
                  }
                  return { remoteScreenShares: newRemoteScreenShares };
                });
              }
            }
          });

          voiceCallApi.on('newProducer', async (producerData) => {
            const state = get();
            // For LiveKit, newProducer is handled by trackSubscribed
            // Only use handleNewProducer for legacy mediasoup compatibility
            if (state.device && state.recvTransport) {
              await state.handleNewProducer(producerData);
            }
          });

          voiceCallApi.on('producerClosed', (data) => {
            console.log('ğŸ¥ Producer closed event received:', data);
            
            const producerId = data.producerId || data;
            const producerSocketId = data.producerSocketId;
            const producerKind = data.kind; // video Ğ¸Ğ»Ğ¸ audio
            const mediaType = data.mediaType; // screen Ğ¸Ğ»Ğ¸ camera
            
            console.log('ğŸ¥ Producer closed parsed:', { producerId, producerSocketId, producerKind, mediaType });
            
            // Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ğ´Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ Ñ‚Ğ¸Ğ¿Ğ° producer
            console.log('ğŸ¥ Producer type analysis:', {
              isVideoProducer: producerKind === 'video' && mediaType === 'camera',
              isAudioProducer: producerKind === 'audio',
              isScreenShare: mediaType === 'screen',
              shouldCleanAudio: producerKind === 'audio' || mediaType === 'screen'
            });
            
            // Ğ—Ğ°Ñ‰Ğ¸Ñ‚Ğ° Ğ¾Ñ‚ Ğ´ÑƒĞ±Ğ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
            const state = get();
            if (state.processedProducers && state.processedProducers.has(producerId)) {
              console.log('ğŸ¥ Producer already processed, ignoring:', producerId);
              return;
            }
            
            // ĞÑ‚Ğ¼ĞµÑ‡Ğ°ĞµĞ¼ producer ĞºĞ°Ğº Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹
            set(state => ({
              processedProducers: new Set([...(state.processedProducers || []), producerId])
            }));
            
            // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ ÑĞºÑ€Ğ°Ğ½Ğ°
            const screenShare = state.remoteScreenShares.get(producerId);
            if (screenShare) {
              console.log('Screen share producer closed:', producerId);
              // ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ñ‚Ğ¾Ğº
              if (screenShare.stream) {
                screenShare.stream.getTracks().forEach(track => track.stop());
              }
              // Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ¸Ğ· Map
              const newRemoteScreenShares = new Map(state.remoteScreenShares);
              newRemoteScreenShares.delete(producerId);
              set({ remoteScreenShares: newRemoteScreenShares });
            }
            
            // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ğ¾Ğ¹ (video producer Ñ mediaType camera)
            const userId = state.peerIdToUserIdMap.get(producerSocketId) || producerSocketId;
            
            // Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾ producer, Ğ½Ğµ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ ĞµĞ³Ğ¾ Ğ·Ğ´ĞµÑÑŒ
            if (producerKind === 'audio' && mediaType !== 'screen') {
              console.log('ğŸ¥ Audio producer closed, ignoring to preserve audio stream');
              return;
            }
            
            // Ğ•ÑĞ»Ğ¸ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ kind Ğ¸ mediaType Ğ½Ğµ Ğ¿Ñ€Ğ¸Ñ…Ğ¾Ğ´ÑÑ‚, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ¿Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°Ğ¼
            let isVideoProducer = false;
            if (producerKind === 'video' && mediaType === 'camera') {
              isVideoProducer = true;
            } else if (mediaType === 'camera') {
              // Ğ•ÑĞ»Ğ¸ mediaType === 'camera', Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ video producer
              console.log('ğŸ¥ Detected video producer by mediaType:', userId);
              isVideoProducer = true;
            } else if (!producerKind && !mediaType) {
              // ĞĞ»ÑŒÑ‚ĞµÑ€Ğ½Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ°: ĞµÑĞ»Ğ¸ Ñƒ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° ĞµÑÑ‚ÑŒ isVideoEnabled, Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ±Ñ‹Ñ‚ÑŒ video producer
              const participant = state.participants.find(p => p.userId === userId);
              if (participant && participant.isVideoEnabled) {
                console.log('ğŸ¥ Detected video producer by participant state:', userId);
                isVideoProducer = true;
              }
            }
            
            if (userId && userId !== state.currentUserId && isVideoProducer) {
              console.log('ğŸ¥ Camera video producer closed for user:', userId);
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹
              set((state) => {
                const newVideoStates = new Map(state.participantVideoStates);
                newVideoStates.set(userId, false);
                return { participantVideoStates: newVideoStates };
              });
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° - Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñƒ (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
              set((state) => {
                const updatedParticipants = state.participants.map(p => 
                  p.userId === userId 
                    ? { ...p, isVideoEnabled: false, videoStream: null }
                    : p
                );
                console.log('ğŸ¥ Updated participants after video close:', updatedParticipants);
                return { participants: updatedParticipants };
              });
            }
            
            // Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ consumer Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ video producer, Ğ½Ğµ Ğ´Ğ»Ñ audio
            if (isVideoProducer || mediaType === 'screen') {
              const consumer = get().consumers.get(producerId);
              if (consumer) {
                console.log('ğŸ¥ Closing consumer for video producer:', producerId, 'kind:', consumer.kind);
                consumer.close();
                set((state) => {
                  const newConsumers = new Map(state.consumers);
                  newConsumers.delete(producerId);
                  return { consumers: newConsumers };
                });
              } else {
                console.log('ğŸ¥ No consumer found for video producer:', producerId);
              }
            } else {
              console.log('ğŸ¥ Preserving consumer for audio producer:', producerId);
              const consumer = get().consumers.get(producerId);
              if (consumer) {
                console.log('ğŸ¥ Audio consumer preserved:', producerId, 'kind:', consumer.kind, 'paused:', consumer.paused);
              } else {
                console.log('ğŸ¥ No audio consumer found for producer:', producerId);
              }
            }
            
            // Ğ’ĞĞ–ĞĞ: ĞĞ• Ğ¾Ñ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ audio elements Ğ¸ gain nodes Ğ´Ğ»Ñ video producer!
            // Audio elements Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ¾ÑÑ‚Ğ°Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¼Ğ¸ Ğ´Ğ»Ñ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°
            // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ¸Ñ… Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ audio producer (ĞĞ• screen share!)
            if (producerSocketId && producerKind === 'audio' && mediaType !== 'screen') {
              const userId = get().peerIdToUserIdMap.get(producerSocketId);
              if (userId) {
                console.log('ğŸ¥ Cleaning up audio elements for audio producer:', producerId);
                // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ audio element Ğ¸ gain node Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ audio producer
                const audioElement = get().audioElements.get(userId);
                if (audioElement) {
                  audioElement.pause();
                  audioElement.srcObject = null;
                  if (audioElement.parentNode) {
                    audioElement.parentNode.removeChild(audioElement);
                  }
                }
                
                const gainNode = get().gainNodes.get(userId);
                if (gainNode) {
                  try {
                    gainNode.disconnect();
                  } catch (e) {
                    console.warn('Error disconnecting gain node:', e);
                  }
                }
                
                set((state) => {
                  const newUserVolumes = new Map(state.userVolumes);
                  const newUserMutedStates = new Map(state.userMutedStates);
                  const newShowVolumeSliders = new Map(state.showVolumeSliders);
                  const newGainNodes = new Map(state.gainNodes);
                  const newAudioElements = new Map(state.audioElements);
                  const newPreviousVolumes = new Map(state.previousVolumes);
                  
                  newUserVolumes.delete(userId);
                  newUserMutedStates.delete(userId);
                  newShowVolumeSliders.delete(userId);
                  newGainNodes.delete(userId);
                  newAudioElements.delete(userId);
                  newPreviousVolumes.delete(userId);
                  
                  return {
                    userVolumes: newUserVolumes,
                    userMutedStates: newUserMutedStates,
                    showVolumeSliders: newShowVolumeSliders,
                    gainNodes: newGainNodes,
                    audioElements: newAudioElements,
                    previousVolumes: newPreviousVolumes
                  };
                });
              }
            } else if (producerSocketId && (isVideoProducer || mediaType === 'screen')) {
              console.log('ğŸ¥ Video/Screen producer closed - preserving audio elements for user:', get().peerIdToUserIdMap.get(producerSocketId));
            }
          });

          // ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
          voiceCallApi.on('globalAudioStateChanged', (data) => {
            const { userId, isGlobalAudioMuted } = data;
            console.log('Global audio state changed for user:', userId, 'muted:', isGlobalAudioMuted);
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
            set((state) => {
              const newGlobalAudioStates = new Map(state.participantGlobalAudioStates);
              newGlobalAudioStates.set(userId, isGlobalAudioMuted);
              return { participantGlobalAudioStates: newGlobalAudioStates };
            });
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
            set((state) => {
              const updatedParticipants = state.participants.map(p => 
                p.userId === userId ? { ...p, isGlobalAudioMuted } : p
              );
              console.log('Updated participants:', updatedParticipants);
              return { participants: updatedParticipants };
            });
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ voiceChannelParticipants
            const currentRoomId = get().currentRoomId;
            if (currentRoomId) {
              get().updateVoiceChannelParticipant(currentRoomId, userId, {
                isGlobalAudioMuted,
                isAudioDisabled: isGlobalAudioMuted,
                isDeafened: isGlobalAudioMuted
              });
            }
          });

          // Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ: ÑĞ»ÑƒÑˆĞ°ĞµĞ¼ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ globalAudioState Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ°
          if (voiceCallApi.socket) {
            voiceCallApi.socket.on('globalAudioState', (data) => {
              console.log('Received globalAudioState from server:', data);
              const { userId, isGlobalAudioMuted } = data;
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
              set((state) => {
                const newGlobalAudioStates = new Map(state.participantGlobalAudioStates);
                newGlobalAudioStates.set(userId, isGlobalAudioMuted);
                return { participantGlobalAudioStates: newGlobalAudioStates };
              });
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾ (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
              set((state) => {
                const updatedParticipants = state.participants.map(p => 
                  p.userId === userId ? { ...p, isGlobalAudioMuted } : p
                );
                console.log('Updated participants with globalAudioState:', updatedParticipants);
                return { participants: updatedParticipants };
              });
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ voiceChannelParticipants
              const currentRoomId = get().currentRoomId;
              if (currentRoomId) {
                get().updateVoiceChannelParticipant(currentRoomId, userId, {
                  isGlobalAudioMuted,
                  isAudioDisabled: isGlobalAudioMuted,
                  isDeafened: isGlobalAudioMuted
                });
              }
            });
          }
          
          set({ isConnected: true, connecting: false, processedProducers: new Set() });
          
          // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€
          if (voiceCallApi.socket) {
            voiceCallApi.socket.emit('muteState', { isMuted: get().isMuted });
            voiceCallApi.socket.emit('audioState', { isEnabled: !get().isGlobalAudioMuted });
          }
        } catch (error) {
          console.error('Failed to initialize call:', error);
          set({ error: error.message, connecting: false });
        }
      },
      
      // ĞŸÑ€Ğ¸ÑĞ¾ĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ Ğº ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚Ğµ
      joinRoom: async (roomId) => {
        const state = get();
        if (!state.isConnected) {
          console.error('Not connected to voice server');
          return;
        }
        
        try {
          console.log('Joining room:', roomId);
          
          // ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ´Ğ»Ñ Ğ¿ĞµÑ€ĞµĞ´Ğ°Ñ‡Ğ¸ Ğ°Ğ²Ğ°Ñ‚Ğ°Ñ€Ğ°
          let userAvatar = null;
          let userAvatarColor = '#5865f2';
          try {
            const profile = await userApi.getProfile(state.currentUserId);
            if (profile) {
              userAvatar = profile.avatar || null;
              userAvatarColor = profile.avatarColor || '#5865f2';
            }
          } catch (err) {
            console.warn('Failed to load profile for joinRoom:', err);
          }
          
          const response = await voiceCallApi.joinRoom(
            roomId, 
            state.currentUserName, 
            state.currentUserId, 
            state.isMuted, 
            !state.isGlobalAudioMuted,
            userAvatar,
            userAvatarColor
          );
          
          // LiveKit doesn't need routerRtpCapabilities or device initialization
          // Audio/video tracks are managed automatically by LiveKit
          
          if (response.existingPeers) {
            // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ¼Ğ°Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ´Ğ»Ñ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰Ğ¸Ñ… Ğ¿Ğ¸Ñ€Ğ¾Ğ²
            const newMap = new Map(state.peerIdToUserIdMap);
            response.existingPeers.forEach(peer => {
              const socketId = peer.peerId || peer.id;
              if (socketId && peer.userId) {
                newMap.set(socketId, peer.userId);
                console.log('[VAD] existingPeers: Added mapping', { socketId, userId: peer.userId });
              }
            });
            console.log('[VAD] existingPeers mappings:', Array.from(newMap.entries()));
            
            // Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ÑƒÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² Ğ±ĞµĞ· Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ĞµĞ¹
            set({
              peerIdToUserIdMap: newMap,
              participants: response.existingPeers.map(peer => ({
                userId: peer.userId,
                peerId: peer.peerId || peer.id,
                name: peer.name,
                isMuted: peer.isMuted || false,
                isAudioEnabled: peer.isAudioEnabled !== undefined ? peer.isAudioEnabled : true,
                isGlobalAudioMuted: peer.isGlobalAudioMuted || false, // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
                isSpeaking: false,
                avatar: null,
                avatarColor: '#5865f2',
                banner: null
              }))
            });
            
            // Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ¸ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
            Promise.all(response.existingPeers.map(async (peer) => {
              try {
                const profile = await userApi.getProfile(peer.userId);
                if (profile) {
                  // ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ banner Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼ Ğ¸Ğ»Ğ¸ Ñ†Ğ²ĞµÑ‚Ğ¾Ğ¼
                  const bannerIsImage = isBannerImage(profile.banner);
                  const bannerValue = profile.banner 
                    ? (bannerIsImage ? `${MEDIA_BASE_URL}${profile.banner}` : profile.banner)
                    : null;
                  
                  const profileData = {
                    avatar: profile.avatar ? `${MEDIA_BASE_URL}${profile.avatar}` : null,
                    avatarColor: profile.avatarColor || '#5865f2',
                    banner: bannerValue
                  };
                  
                  // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ñ
                  set((state) => ({
                    participants: state.participants.map(p => 
                      p.userId === peer.userId 
                        ? { ...p, ...profileData }
                        : p
                    )
                  }));
                }
              } catch (error) {
                console.warn('Failed to load profile for existing peer:', peer.userId, error);
              }
            })).catch(error => {
              console.warn('Error loading profiles for existing peers:', error);
            });
          }
          
          if (response.existingProducers && response.existingProducers.length > 0) {
            for (const producer of response.existingProducers) {
              try {
                await state.handleNewProducer(producer);
              } catch (error) {
                console.error('Failed to process existing producer:', error);
              }
            }
          }
          
          // Ğ”Ğ»Ñ LiveKit Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¸ Ğº ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚Ğµ
          // ĞĞ¾ Ğ¼Ñ‹ Ğ²ÑĞµ Ñ€Ğ°Ğ²Ğ½Ğ¾ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ´Ğ»Ñ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
          await state.createAudioStream();
          
          // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ° Ğ¸ Ğ½Ğ°ÑƒÑˆĞ½Ğ¸ĞºĞ¾Ğ² Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€
          const currentState = get();
          if (voiceCallApi.socket) {
            // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
            voiceCallApi.socket.emit('muteState', { isMuted: currentState.isMuted });
            console.log('ğŸ“¤ Initial mic state sent to server:', currentState.isMuted);
            
            // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ½Ğ°ÑƒÑˆĞ½Ğ¸ĞºĞ¾Ğ²
            voiceCallApi.socket.emit('audioState', { 
              isEnabled: !currentState.isGlobalAudioMuted,
              isGlobalAudioMuted: currentState.isGlobalAudioMuted,
              userId: currentState.currentUserId
            });
            console.log('ğŸ“¤ Initial audio state sent to server:', !currentState.isGlobalAudioMuted);
          }
          
          set({ currentRoomId: roomId, isInCall: true, currentCall: { channelId: roomId, channelName: roomId } });
          
          // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ voiceChannelParticipants Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ ĞºĞ°Ğ½Ğ°Ğ»Ğ¾Ğ²
          const afterJoinState = get();
          const currentUserData = {
            odUserId: afterJoinState.currentUserId,
            userName: afterJoinState.currentUserName,
            isMuted: afterJoinState.isMuted,
            isGlobalAudioMuted: afterJoinState.isGlobalAudioMuted || false,
            isAudioDisabled: afterJoinState.isGlobalAudioMuted || false,
            isDeafened: afterJoinState.isGlobalAudioMuted || false,
            avatar: null,
            avatarColor: '#5865f2'
          };
          
          // Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
          try {
            const profile = await userApi.getProfile(afterJoinState.currentUserId);
            if (profile) {
              currentUserData.avatar = profile.avatar ? `${MEDIA_BASE_URL}${profile.avatar}` : null;
              currentUserData.avatarColor = profile.avatarColor || '#5865f2';
            }
          } catch (e) {
            console.warn('Failed to load current user profile for voice channel:', e);
          }
          
          // Ğ¤Ğ¾Ñ€Ğ¼Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¿Ğ¸ÑĞ¾Ğº ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² ĞºĞ°Ğ½Ğ°Ğ»Ğ°
          const channelParticipants = [
            currentUserData,
            ...afterJoinState.participants.map(p => ({
              odUserId: p.userId,
              userName: p.name || p.userName,
              isMuted: p.isMuted,
              isGlobalAudioMuted: p.isGlobalAudioMuted || false,
              isAudioDisabled: p.isGlobalAudioMuted || false,
              isDeafened: p.isGlobalAudioMuted || false,
              avatar: p.avatar,
              avatarColor: p.avatarColor || '#5865f2'
            }))
          ];
          
          get().setVoiceChannelParticipants(roomId, channelParticipants);
          console.log('ğŸ“¢ Voice channel participants updated:', channelParticipants);
          
          // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
          audioNotificationManager.playUserJoinedSound().catch(error => {
            console.warn('Failed to play user joined sound for self:', error);
          });
        } catch (error) {
          console.error('Failed to join room:', error);
          set({ error: error.message });
        }
      },
      
      // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑƒÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ°
      initializeDevice: async (routerRtpCapabilities) => {
        try {
          const device = await voiceCallApi.initializeDevice(routerRtpCapabilities);
          set({ device });
          await get().createTransports();
        } catch (error) {
          console.error('Failed to initialize device:', error);
          set({ error: error.message });
        }
      },
      
      // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ñ‚Ñ€Ğ°Ğ½ÑĞ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ²
      createTransports: async () => {
        try {
          const state = get();
          if (!state.device) return;
          
          // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ send transport
          const sendTransportData = await voiceCallApi.createWebRtcTransport();
          const sendTransport = state.device.createSendTransport({
            id: sendTransportData.id,
            iceParameters: sendTransportData.iceParameters,
            iceCandidates: sendTransportData.iceCandidates,
            dtlsParameters: sendTransportData.dtlsParameters,
            iceServers: ICE_SERVERS
          });

          sendTransport.on('connect', async ({ dtlsParameters }, callback, errback) => {
            try {
              await voiceCallApi.connectTransport(sendTransportData.id, dtlsParameters);
              callback();
            } catch (error) {
              errback(error);
            }
          });

          sendTransport.on('produce', async ({ kind, rtpParameters, appData }, callback, errback) => {
            try {
              const { id } = await voiceCallApi.produce(sendTransportData.id, kind, rtpParameters, appData);
              callback({ id });
            } catch (error) {
              errback(error);
            }
          });

          // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ recv transport
          const recvTransportData = await voiceCallApi.createWebRtcTransport();
          const recvTransport = state.device.createRecvTransport({
            id: recvTransportData.id,
            iceParameters: recvTransportData.iceParameters,
            iceCandidates: recvTransportData.iceCandidates,
            dtlsParameters: recvTransportData.dtlsParameters,
            iceServers: ICE_SERVERS
          });

          recvTransport.on('connect', async ({ dtlsParameters }, callback, errback) => {
            try {
              await voiceCallApi.connectTransport(recvTransportData.id, dtlsParameters);
              callback();
            } catch (error) {
              errback(error);
            }
          });

          set({ sendTransport, recvTransport });
          console.log('Transports created');
        } catch (error) {
          console.error('Failed to create transports:', error);
          set({ error: error.message });
        }
      },
      
      // ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ producer
      handleNewProducer: async (producerData) => {
        try {
          const state = get();
          if (!state.device || !state.recvTransport) return;
          
          const consumerData = await voiceCallApi.consume(
            state.device.rtpCapabilities,
            producerData.producerId,
            state.recvTransport.id
          );

          const consumer = await state.recvTransport.consume({
            id: consumerData.id,
            producerId: producerData.producerId,
            kind: producerData.kind,
            rtpParameters: consumerData.rtpParameters
          });

          set((state) => {
            const newConsumers = new Map(state.consumers);
            newConsumers.set(consumerData.id, consumer);
            return { consumers: newConsumers };
          });
          
          const socketId = producerData.producerSocketId;
          const userId = state.peerIdToUserIdMap.get(socketId) || socketId;
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸ĞµĞ¹ ÑĞºÑ€Ğ°Ğ½Ğ°
          const isScreenShare = producerData.appData?.mediaType === 'screen';
          console.log('callStore handleNewProducer: isScreenShare=', isScreenShare, 'kind=', producerData.kind, 'userId=', userId, 'currentUserId=', state.currentUserId, 'producerUserId=', producerData.appData?.userId);
          
          // Ğ”Ğ»Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑ€Ğ°Ğ½Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ video Ğ¸ audio Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾
          if (isScreenShare) {
            // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ ÑÑ‚Ğ¾ Ğ½Ğµ Ğ½Ğ°ÑˆĞ° ÑĞ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ğ°Ñ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞºÑ€Ğ°Ğ½Ğ°
            const producerUserId = producerData.appData?.userId;
            if (producerUserId === state.currentUserId) {
              console.log('Skipping own screen share producer in handleNewProducer', { userId, currentUserId: state.currentUserId, producerUserId });
              return;
            }
            
            console.log('Screen share producer detected in callStore:', { kind: producerData.kind, userId });
            
            if (producerData.kind === 'video') {
              // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ MediaStream Ğ¸Ğ· consumer track Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ
              const screenStream = new MediaStream([consumer.track]);
              
              const currentState = get();
              const newRemoteScreenShares = new Map(currentState.remoteScreenShares);
              newRemoteScreenShares.set(producerData.producerId, {
                stream: screenStream,
                producerId: producerData.producerId,
                userId: userId,
                userName: producerData.appData?.userName || 'Unknown',
                socketId: socketId
              });
              
              set({ remoteScreenShares: newRemoteScreenShares });
            } else if (producerData.kind === 'audio') {
              console.log('Screen share audio producer detected, creating audio element');
              
              // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ audio element Ğ´Ğ»Ñ screen share audio
              const audioElement = document.createElement('audio');
              audioElement.srcObject = new MediaStream([consumer.track]);
              audioElement.autoplay = true;
              audioElement.volume = 1.0; // ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ screen share audio
              audioElement.muted = false;
              audioElement.playsInline = true;
              audioElement.controls = false;
              audioElement.style.display = 'none';
              
              // Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² DOM Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ñ
              document.body.appendChild(audioElement);
              
              // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ audio element Ğ´Ğ»Ñ screen share audio
              const screenShareAudioKey = `screen-share-audio-${userId}`;
              const currentState = get();
              const newAudioElements = new Map(currentState.audioElements);
              newAudioElements.set(screenShareAudioKey, audioElement);
              
              set({ audioElements: newAudioElements });
              
              console.log('Screen share audio element created:', screenShareAudioKey);
            }
            
            return;
          }

          // ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° video producers (Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ğ°)
          if (producerData.kind === 'video' && producerData.appData?.mediaType === 'camera') {
            console.log('ğŸ¥ Camera video producer detected, updating participant video stream');
            console.log('ğŸ¥ Producer data:', { userId, producerUserId: producerData.appData?.userId, currentUserId: state.currentUserId });
            
            // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ ÑƒĞ¶Ğµ videoStream Ñƒ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°
            const existingParticipant = state.participants.find(p => p.userId === userId);
            if (existingParticipant && existingParticipant.videoStream) {
              console.log('ğŸ¥ Participant already has video stream, skipping creation');
              return;
            }
            
            // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ MediaStream Ğ¸Ğ· consumer track
            const videoStream = new MediaStream([consumer.track]);
            console.log('ğŸ¥ Created video stream:', videoStream);
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ° Ñ video stream
            set((state) => {
              const updatedParticipants = state.participants.map(p => 
                p.userId === userId 
                  ? { ...p, isVideoEnabled: true, videoStream: videoStream }
                  : p
              );
              console.log('ğŸ¥ Updated participants:', updatedParticipants);
              return { participants: updatedParticipants };
            });
            
            return;
          }
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ AudioContext ĞµÑĞ»Ğ¸ ĞµÑ‰Ğµ Ğ½Ğµ ÑĞ¾Ğ·Ğ´Ğ°Ğ½
          let audioContext = state.audioContext;
          if (!audioContext || audioContext.state === 'closed') {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 48000,
              latencyHint: 'interactive'
            });
            set({ audioContext });
          }
          
          if (audioContext.state === 'suspended') {
            await audioContext.resume();
          }
          
          // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ audio element
          const audioElement = document.createElement('audio');
          audioElement.srcObject = new MediaStream([consumer.track]);
          audioElement.autoplay = true;
          audioElement.playsInline = true;
          audioElement.controls = false;
          audioElement.style.display = 'none';
          document.body.appendChild(audioElement);
          
          // Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Web Audio API chain
          const source = audioContext.createMediaStreamSource(new MediaStream([consumer.track]));
          const gainNode = audioContext.createGain();
          source.connect(gainNode);
          
          // Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ½Ğ°Ñ‡Ğ°Ğ»ÑŒĞ½ÑƒÑ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚ÑŒ
          const initialVolume = state.userVolumes.get(userId) || 100;
          const isMuted = state.userMutedStates.get(userId) || false;
          const audioVolume = state.isGlobalAudioMuted ? 0 : (isMuted ? 0 : (initialVolume / 100.0));
          audioElement.volume = audioVolume;
          
          // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸
          set((state) => {
            const newGainNodes = new Map(state.gainNodes);
            const newAudioElements = new Map(state.audioElements);
            newGainNodes.set(userId, gainNode);
            newAudioElements.set(userId, audioElement);
            
            const newUserVolumes = new Map(state.userVolumes);
            if (!newUserVolumes.has(userId)) {
              newUserVolumes.set(userId, 100);
            }
            
            return {
              gainNodes: newGainNodes,
              audioElements: newAudioElements,
              userVolumes: newUserVolumes
            };
          });
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Voice Activity Detection (VAD) Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ°
          try {
            const remoteStream = new MediaStream([consumer.track]);
            await get().initializeRemoteVAD(userId, remoteStream, audioContext);
          } catch (vadError) {
            console.warn('[VAD] Failed to initialize remote VAD for user:', userId, vadError);
          }

          try {
            await audioElement.play();
            console.log('Audio playback started for peer:', userId);
            set({ audioBlocked: false });
          } catch (error) {
            console.log('Auto-play blocked, user interaction required:', error);
            set({ audioBlocked: true });
            setTimeout(async () => {
              try {
                await audioElement.play();
                set({ audioBlocked: false });
              } catch {
                console.log('Audio playback still blocked');
              }
            }, 1000);
          }

          await voiceCallApi.resumeConsumer(consumerData.id);
          console.log('New consumer created:', consumerData.id);
        } catch (error) {
          console.error('Failed to handle new producer:', error);
        }
      },
      
      // Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞ°
      // Ğ”Ğ»Ñ LiveKit Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¸ Ğº ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚Ğµ
      // Ğ­Ñ‚Ğ¾Ñ‚ Ğ¼ĞµÑ‚Ğ¾Ğ´ Ñ‚ĞµĞ¿ĞµÑ€ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ
      createAudioStream: async () => {
        try {
          const state = get();
          
          // Ğ”Ğ»Ñ LiveKit Ğ½Ğµ Ğ½ÑƒĞ¶ĞµĞ½ sendTransport - Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ÑÑ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ñ‹ Ğ»Ğ¸ Ğ¼Ñ‹ Ğº LiveKit ĞºĞ¾Ğ¼Ğ½Ğ°Ñ‚Ğµ
          const room = voiceCallApi.getRoom();
          if (!room) {
            console.warn('No LiveKit room available, skipping audio stream creation');
            return;
          }
          
          // ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
          if (state.localStream) {
            state.localStream.getTracks().forEach(track => track.stop());
          }
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑÑ‚Ğ°Ñ€Ğ¾Ğµ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ (ĞµÑĞ»Ğ¸ Ğ±Ñ‹Ğ»Ğ¾ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ Ñ€Ğ°Ğ½ĞµĞµ)
          if (state.noiseSuppressionManager) {
            state.noiseSuppressionManager.cleanup();
          }
          
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
              sampleRate: 48000,
              channelCount: 1,
              latency: 0,
              suppressLocalAudioPlayback: true
            }
          });

          set({ localStream: stream, audioStream: stream });
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ audio context
          let audioContext = state.audioContext;
          if (!audioContext || audioContext.state === 'closed') {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 48000,
              latencyHint: 'interactive'
            });
            set({ audioContext });
          }
          
          if (audioContext.state === 'suspended') {
            await audioContext.resume();
          }
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
          const noiseSuppressionManager = new NoiseSuppressionManager();
          await noiseSuppressionManager.initialize(stream, audioContext);
          set({ noiseSuppressionManager });
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Voice Activity Detection (VAD) Ğ´Ğ»Ñ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
          try {
            await get().initializeLocalVAD(stream, audioContext);
          } catch (vadError) {
            console.warn('[VAD] Failed to initialize local VAD:', vadError);
          }
          
          // Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ÑĞ»ÑƒÑˆĞ°Ñ‚ĞµĞ»Ñ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¾Ñ‚ ÑĞµÑ€Ğ²ĞµÑ€Ğ° (Ğ´Ğ»Ñ ÑƒĞ´Ğ°Ğ»Ñ‘Ğ½Ğ½Ñ‹Ñ… ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²)
          try {
            get().initializeSpeakingStateListener();
          } catch (listenerError) {
            console.warn('[VAD] Failed to initialize speaking state listener:', listenerError);
          }
          
          // ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº (Ñ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼, ĞµÑĞ»Ğ¸ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾)
          const processedStream = noiseSuppressionManager.getProcessedStream();
          const audioTrack = processedStream ? processedStream.getAudioTracks()[0] : stream.getAudioTracks()[0];
          
          if (!audioTrack) {
            throw new Error('No audio track in stream');
          }
          
          // Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
          audioTrack.enabled = !state.isMuted;
          
          // Ğ•ÑĞ»Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ, Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ ĞµĞ³Ğ¾
          const savedNoiseSuppression = localStorage.getItem('noiseSuppression');
          const isNoiseSuppressed = savedNoiseSuppression ? JSON.parse(savedNoiseSuppression) : false;
          if (isNoiseSuppressed) {
            await noiseSuppressionManager.enable(state.noiseSuppressionMode || 'rnnoise');
            set({ isNoiseSuppressed: true });
            
            // ĞŸÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº Ğ² LiveKit
            const processedStream = noiseSuppressionManager.getProcessedStream();
            if (processedStream) {
              const processedTrack = processedStream.getAudioTracks()[0];
              if (processedTrack) {
                try {
                  // ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¾Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½
                  await room.localParticipant.setMicrophoneEnabled(false);
                  
                  // ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
                  const microphonePublication = room.localParticipant.getTrackPublication('microphone');
                  
                  if (microphonePublication && microphonePublication.track) {
                    // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ replaceTrack Ğ½Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼ Ñ‚Ñ€ĞµĞºĞµ (Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸)
                    console.log('Replacing existing microphone track with noise suppression using replaceTrack');
                    await microphonePublication.track.replaceTrack(processedTrack);
                    console.log('Audio track with noise suppression replaced via LiveKit');
                  } else {
                    // Ğ•ÑĞ»Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ½ĞµÑ‚, Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº
                    console.log('No existing microphone publication, publishing new track with noise suppression');
                    await room.localParticipant.setMicrophoneEnabled(false);
                    await room.localParticipant.publishTrack(processedTrack, {
                      source: Track.Source.Microphone,
                      name: 'microphone'
                    });
                    console.log('Audio track with noise suppression published via LiveKit');
                  }
                  
                  // Ğ’ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½ Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¼ Ñ‚Ñ€ĞµĞºĞ¾Ğ¼
                  await room.localParticipant.setMicrophoneEnabled(!state.isMuted);
                } catch (error) {
                  console.warn('Failed to publish processed track via LiveKit:', error);
                  // Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¾Ğ±Ñ‹Ñ‡Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº
                  await room.localParticipant.setMicrophoneEnabled(!state.isMuted);
                }
              }
            }
          } else {
            // Ğ”Ğ»Ñ LiveKit Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµĞ¼ Ñ‚Ñ€ĞµĞº Ñ‡ĞµÑ€ĞµĞ· localParticipant
            // LiveKit Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµÑ‚ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½ Ğ¿Ñ€Ğ¸ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¸, Ğ½Ğ¾ Ğ¼Ñ‹ Ğ¼Ğ¾Ğ¶ĞµĞ¼ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ Ñ‚Ñ€ĞµĞº
            try {
              await room.localParticipant.setMicrophoneEnabled(!state.isMuted);
              console.log('Audio track published via LiveKit');
            } catch (error) {
              console.warn('Failed to publish audio track via LiveKit:', error);
            }
          }
          
          console.log('Audio stream created with noise suppression support');
        } catch (error) {
          console.error('Failed to create audio stream:', error);
          set({ error: error.message });
        }
      },
      
      // ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
      toggleMute: async () => {
        const state = get();
        const newMutedState = !state.isMuted;
        
        // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ² localStorage
        localStorage.setItem('micMuted', JSON.stringify(newMutedState));
        console.log('ğŸ’¾ Mic state saved to localStorage:', newMutedState);
        
        // Use LiveKit API to toggle microphone
        try {
          await voiceCallApi.setMicrophoneEnabled(!newMutedState);
        } catch (error) {
          console.warn('Failed to toggle microphone via LiveKit:', error);
          // Fallback to local track control
          if (state.noiseSuppressionManager) {
            const processedStream = state.noiseSuppressionManager.getProcessedStream();
            const audioTrack = processedStream?.getAudioTracks()[0];
            if (audioTrack) {
              audioTrack.enabled = !newMutedState;
            }
          } else if (state.localStream) {
            const audioTrack = state.localStream.getAudioTracks()[0];
            if (audioTrack) {
              audioTrack.enabled = !newMutedState;
            }
          }
        }
        
        set({ isMuted: newMutedState });
        
        // Ğ¡Ğ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ¾Ğ²Ğ¾Ñ€ĞµĞ½Ğ¸Ñ Ğ¿Ñ€Ğ¸ Ğ¼ÑŒÑÑ‚Ğµ
        if (newMutedState) {
          const userId = state.currentUserId;
          if (userId) {
            get().resetSpeakingState(userId);
            // Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¿Ñ€Ğ¸Ğ½ÑƒĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ ÑĞ±Ñ€Ğ°ÑÑ‹Ğ²Ğ°ĞµĞ¼ VAD Ğ´ĞµÑ‚ĞµĞºÑ‚Ğ¾Ñ€
            const vadDetector = get().localVoiceActivityDetector;
            if (vadDetector && vadDetector.forceReset) {
              vadDetector.forceReset();
            }
            console.log('[VAD] Reset speaking state due to mute for user:', userId);
          }
        }
        
        // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ¼ÑŒÑÑ‚Ğ°/Ñ€Ğ°Ğ·Ğ¼ÑŒÑÑ‚Ğ° (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾)
        if (newMutedState) {
          audioNotificationManager.playMicMutedSound().catch(error => {
            console.warn('Failed to play mic muted sound:', error);
          });
        } else {
          audioNotificationManager.playMicUnmutedSound().catch(error => {
            console.warn('Failed to play mic unmuted sound:', error);
          });
        }
      },
      
      // ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼ÑƒÑ‚Ğ° Ğ´Ğ»Ñ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
      toggleUserMute: (peerId) => {
        const state = get();
        const audioElement = state.audioElements.get(peerId);
        if (!audioElement) return;

        const isCurrentlyMuted = state.userMutedStates.get(peerId) || false;
        const newIsMuted = !isCurrentlyMuted;

        if (newIsMuted) {
          const currentVolume = state.userVolumes.get(peerId) || 100;
          set((state) => {
            const newPreviousVolumes = new Map(state.previousVolumes);
            newPreviousVolumes.set(peerId, currentVolume);
            return { previousVolumes: newPreviousVolumes };
          });
          audioElement.volume = 0;
        } else {
          const currentVolume = state.userVolumes.get(peerId) || 100;
          const audioVolume = state.isGlobalAudioMuted ? 0 : (currentVolume / 100.0);
          audioElement.volume = audioVolume;
        }

        set((state) => {
          const newUserMutedStates = new Map(state.userMutedStates);
          newUserMutedStates.set(peerId, newIsMuted);
          return { userMutedStates: newUserMutedStates };
        });
      },
      
      // Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
      changeUserVolume: (peerId, newVolume) => {
        const state = get();
        const audioElement = state.audioElements.get(peerId);
        if (!audioElement) return;

        const audioVolume = state.isGlobalAudioMuted ? 0 : (newVolume / 100.0);
        audioElement.volume = audioVolume;

        set((state) => {
          const newUserVolumes = new Map(state.userVolumes);
          newUserVolumes.set(peerId, newVolume);
          return { userVolumes: newUserVolumes };
        });

        // Ğ•ÑĞ»Ğ¸ Ñ€Ğ°Ğ·Ğ¼ÑƒÑ‚Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· ÑĞ»Ğ°Ğ¹Ğ´ĞµÑ€, Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼ÑƒÑ‚Ğ°
        if (newVolume > 0 && state.userMutedStates.get(peerId)) {
          set((state) => {
            const newUserMutedStates = new Map(state.userMutedStates);
            newUserMutedStates.set(peerId, false);
            return { userMutedStates: newUserMutedStates };
          });
        } else if (newVolume === 0 && !state.userMutedStates.get(peerId)) {
          set((state) => {
            const newUserMutedStates = new Map(state.userMutedStates);
            newUserMutedStates.set(peerId, true);
            return { userMutedStates: newUserMutedStates };
          });
        }
      },
      
      // ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ ÑĞ»Ğ°Ğ¹Ğ´ĞµÑ€Ğ° Ğ³Ñ€Ğ¾Ğ¼ĞºĞ¾ÑÑ‚Ğ¸
      toggleVolumeSlider: (peerId) => {
        set((state) => {
          const newShowVolumeSliders = new Map(state.showVolumeSliders);
          const currentState = newShowVolumeSliders.get(peerId) || false;
          newShowVolumeSliders.set(peerId, !currentState);
          return { showVolumeSliders: newShowVolumeSliders };
        });
      },
      
      // Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ/Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ·Ğ²ÑƒĞºĞ° Ğ²ÑĞµÑ… ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
      toggleGlobalAudio: () => {
        const state = get();
        const newMutedState = !state.isGlobalAudioMuted;
        
        // Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ² localStorage
        localStorage.setItem('audioMuted', JSON.stringify(newMutedState));
        console.log('ğŸ’¾ Audio (headphones) state saved to localStorage:', newMutedState);
        
        // ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ½Ğ°ÑƒÑˆĞ½Ğ¸ĞºĞ¾Ğ² Ğ½Ğ° ÑĞµÑ€Ğ²ĞµÑ€ (ĞºĞ°Ğº Ğ² ÑÑ‚Ğ°Ñ€Ğ¾Ğ¼ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğµ)
        if (voiceCallApi.socket) {
          const audioStateData = { 
            isEnabled: !newMutedState,
            isGlobalAudioMuted: newMutedState,
            userId: get().currentUserId
          };
          console.log('Sending audioState to server:', audioStateData);
          voiceCallApi.socket.emit('audioState', audioStateData);
        }
        
        // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ isAudioEnabled Ğ² ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ğ¸ Ñ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¼ Ğ·Ğ²ÑƒĞºĞ¾Ğ¼
        set({ isGlobalAudioMuted: newMutedState, isAudioEnabled: !newMutedState });
        
        // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ° Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        set((state) => {
          const newGlobalAudioStates = new Map(state.participantGlobalAudioStates);
          newGlobalAudioStates.set(state.currentUserId, newMutedState);
          return { participantGlobalAudioStates: newGlobalAudioStates };
        });
        
        // Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ² ÑĞ¿Ğ¸ÑĞºĞµ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ² (Ğ´Ğ»Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸)
        set((state) => ({
          participants: state.participants.map(p => {
            if (p.userId === state.currentUserId) {
              return { ...p, isGlobalAudioMuted: newMutedState, isAudioEnabled: !newMutedState };
            }
            return p;
          })
        }));
        
        // Ğ¢Ğ°ĞºĞ¶Ğµ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğµ Ğ´Ğ»Ñ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ·Ğ²ÑƒĞºĞ°
        if (voiceCallApi.socket) {
          console.log('Sending globalAudioState to server:', { 
            userId: state.currentUserId,
            isGlobalAudioMuted: newMutedState 
          });
          voiceCallApi.socket.emit('globalAudioState', { 
            userId: state.currentUserId,
            isGlobalAudioMuted: newMutedState 
          });
        }
        
        // Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ HTML Audio ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
        state.audioElements.forEach((audioElement, peerId) => {
          if (audioElement) {
            if (newMutedState) {
              audioElement.volume = 0;
            } else {
              const volume = state.userVolumes.get(peerId) || 100;
              const isIndividuallyMuted = state.userMutedStates.get(peerId) || false;
              const audioVolume = isIndividuallyMuted ? 0 : (volume / 100.0);
              audioElement.volume = audioVolume;
            }
          }
        });
        
        // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ¼ÑŒÑÑ‚Ğ°/Ñ€Ğ°Ğ·Ğ¼ÑŒÑÑ‚Ğ° (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾)
        if (newMutedState) {
          audioNotificationManager.playGlobalMutedSound().catch(error => {
            console.warn('Failed to play global muted sound:', error);
          });
        } else {
          audioNotificationManager.playGlobalUnmutedSound().catch(error => {
            console.warn('Failed to play global unmuted sound:', error);
          });
        }
      },
      
      // ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
      toggleNoiseSuppression: async () => {
        try {
          const state = get();
          if (!state.noiseSuppressionManager || !state.noiseSuppressionManager.isInitialized()) {
            console.error('Noise suppression not initialized');
            return false;
          }

          const newState = !state.isNoiseSuppressed;
          let success = false;

          if (newState) {
            success = await state.noiseSuppressionManager.enable(state.noiseSuppressionMode);
          } else {
            success = await state.noiseSuppressionManager.disable();
          }

          if (success) {
            set({ isNoiseSuppressed: newState });
            localStorage.setItem('noiseSuppression', JSON.stringify(newState));
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ° Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ñ‚Ñ€ĞµĞºĞ°
            if (state.noiseSuppressionManager) {
              const processedStream = state.noiseSuppressionManager.getProcessedStream();
              const audioTrack = processedStream?.getAudioTracks()[0];
              if (audioTrack) {
                audioTrack.enabled = !state.isMuted;
              }
            }
            
            // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ñ€ĞµĞº Ğ² LiveKit Ñ‡ĞµÑ€ĞµĞ· unpublishTrack Ğ¸ publishTrack
            const room = voiceCallApi.getRoom();
            if (room) {
              const localParticipant = room.localParticipant;
              let trackToPublish = null;
              
              if (newState) {
                // ĞŸÑ€Ğ¸ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº
                const processedStream = state.noiseSuppressionManager.getProcessedStream();
                if (processedStream) {
                  trackToPublish = processedStream.getAudioTracks()[0];
                }
              } else {
                // ĞŸÑ€Ğ¸ Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº Ğ¸Ğ· localStream
                // Ğ­Ñ‚Ğ¾ Ğ³Ğ°Ñ€Ğ°Ğ½Ñ‚Ğ¸Ñ€ÑƒĞµÑ‚, Ñ‡Ñ‚Ğ¾ Ğ¼Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº Ğ¸Ğ· getUserMedia
                if (state.localStream) {
                  const originalTrack = state.localStream.getAudioTracks()[0];
                  if (originalTrack && originalTrack.readyState === 'live') {
                    trackToPublish = originalTrack;
                    console.log('Using original track from localStream for LiveKit, readyState:', originalTrack.readyState);
                  } else {
                    console.warn('Original track from localStream is not live (readyState:', originalTrack?.readyState, '), trying noise suppression manager');
                    // Fallback Ğ½Ğ° Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¸Ğ· noiseSuppressionManager
                    const originalStream = state.noiseSuppressionManager.getOriginalStream();
                    if (originalStream) {
                      const managerOriginalTrack = originalStream.getAudioTracks()[0];
                      if (managerOriginalTrack && managerOriginalTrack.readyState === 'live') {
                        trackToPublish = managerOriginalTrack;
                        console.log('Using original track from noiseSuppressionManager');
                      } else {
                        // ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ fallback - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº (passthrough)
                        const processedStream = state.noiseSuppressionManager.getProcessedStream();
                        if (processedStream) {
                          trackToPublish = processedStream.getAudioTracks()[0];
                          console.log('Using processed stream as fallback');
                        }
                      }
                    } else {
                      // ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ fallback - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº (passthrough)
                      const processedStream = state.noiseSuppressionManager.getProcessedStream();
                      if (processedStream) {
                        trackToPublish = processedStream.getAudioTracks()[0];
                        console.log('Using processed stream as fallback (no original stream)');
                      }
                    }
                  }
                } else {
                  console.warn('localStream not available, trying noise suppression manager');
                  // Fallback Ğ½Ğ° Ğ¾Ñ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¸Ğ· noiseSuppressionManager
                  const originalStream = state.noiseSuppressionManager.getOriginalStream();
                  if (originalStream) {
                    const originalTrack = originalStream.getAudioTracks()[0];
                    if (originalTrack && originalTrack.readyState === 'live') {
                      trackToPublish = originalTrack;
                      console.log('Using original track from noiseSuppressionManager');
                    } else {
                      // ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ fallback - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº (passthrough)
                      const processedStream = state.noiseSuppressionManager.getProcessedStream();
                      if (processedStream) {
                        trackToPublish = processedStream.getAudioTracks()[0];
                        console.log('Using processed stream as fallback');
                      }
                    }
                  } else {
                    // ĞŸĞ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¹ fallback - Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ‚Ğ¾Ğº (passthrough)
                    const processedStream = state.noiseSuppressionManager.getProcessedStream();
                    if (processedStream) {
                      trackToPublish = processedStream.getAudioTracks()[0];
                      console.log('Using processed stream as final fallback');
                    }
                  }
                }
              }
              
              if (trackToPublish) {
                try {
                  const wasMuted = state.isMuted;
                  
                  // ĞŸĞ¾Ğ»ÑƒÑ‡Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
                  const microphonePublication = localParticipant.getTrackPublication('microphone');
                  
                  if (microphonePublication && microphonePublication.track) {
                    // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ replaceTrack Ğ½Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼ Ñ‚Ñ€ĞµĞºĞµ (Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸)
                    console.log('Replacing existing microphone track using replaceTrack');
                    await microphonePublication.track.replaceTrack(trackToPublish);
                    console.log('LiveKit track replaced with noise suppression:', newState, 'track readyState:', trackToPublish.readyState);
                  } else {
                    // Ğ•ÑĞ»Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ½ĞµÑ‚, Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº
                    console.log('No existing microphone publication, publishing new track');
                    await localParticipant.setMicrophoneEnabled(false);
                    await localParticipant.publishTrack(trackToPublish, {
                      source: Track.Source.Microphone,
                      name: 'microphone'
                    });
                    console.log('LiveKit track published with noise suppression:', newState, 'track readyState:', trackToPublish.readyState);
                  }
                  
                  // Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
                  await localParticipant.setMicrophoneEnabled(!wasMuted);
                } catch (error) {
                  console.warn('Failed to replace LiveKit track:', error);
                  // Ğ’ ÑĞ»ÑƒÑ‡Ğ°Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾
                  await localParticipant.setMicrophoneEnabled(!state.isMuted);
                }
              } else {
                console.warn('No track available to publish in LiveKit');
              }
            }
            
            return true;
          }
          
          return false;
        } catch (error) {
          console.error('Error toggling noise suppression:', error);
          return false;
        }
      },
      
      // Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
      changeNoiseSuppressionMode: async (mode) => {
        try {
          const state = get();
          if (!state.noiseSuppressionManager || !state.noiseSuppressionManager.isInitialized()) {
            console.error('Noise suppression not initialized');
            return false;
          }

          // Ğ•ÑĞ»Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾, Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼
          if (state.isNoiseSuppressed) {
            // Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¾Ñ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
            await state.noiseSuppressionManager.disable();
            // Ğ—Ğ°Ñ‚ĞµĞ¼ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ€ĞµĞ¶Ğ¸Ğ¼
            const success = await state.noiseSuppressionManager.enable(mode);
            if (success) {
              set({ noiseSuppressionMode: mode });
              
              // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ñ‚Ñ€ĞµĞº Ğ² LiveKit
              const room = voiceCallApi.getRoom();
              if (room) {
                const localParticipant = room.localParticipant;
                const processedStream = state.noiseSuppressionManager.getProcessedStream();
                if (processedStream) {
                  const newTrack = processedStream.getAudioTracks()[0];
                  if (newTrack) {
                    try {
                      const wasMuted = state.isMuted;
                      const microphonePublication = localParticipant.getTrackPublication('microphone');
                      
                      if (microphonePublication && microphonePublication.track) {
                        // Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ replaceTrack Ğ½Ğ° ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ĞµĞ¼ Ñ‚Ñ€ĞµĞºĞµ (Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑƒÑ‚ĞµÑ‡ĞºĞ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸)
                        console.log('Replacing existing microphone track with new noise suppression mode using replaceTrack');
                        await microphonePublication.track.replaceTrack(newTrack);
                        console.log('LiveKit track replaced with new noise suppression mode:', mode);
                      } else {
                        // Ğ•ÑĞ»Ğ¸ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸ Ğ½ĞµÑ‚, Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºÑƒĞµĞ¼ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ñ‚Ñ€ĞµĞº
                        console.log('No existing microphone publication, publishing new track');
                        await localParticipant.setMicrophoneEnabled(false);
                        await localParticipant.publishTrack(newTrack, {
                          source: Track.Source.Microphone,
                          name: 'microphone'
                        });
                        console.log('LiveKit track published with new noise suppression mode:', mode);
                      }
                      
                      // Ğ’Ğ¾ÑÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¼Ğ¸ĞºÑ€Ğ¾Ñ„Ğ¾Ğ½Ğ°
                      await localParticipant.setMicrophoneEnabled(!wasMuted);
                    } catch (error) {
                      console.warn('Failed to replace LiveKit track:', error);
                      await localParticipant.setMicrophoneEnabled(!state.isMuted);
                    }
                  }
                }
              }
              
              return true;
            }
            return false;
          } else {
            // Ğ•ÑĞ»Ğ¸ ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ¾, Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼
            set({ noiseSuppressionMode: mode });
            return true;
          }
        } catch (error) {
          console.error('Error changing noise suppression mode:', error);
          return false;
        }
      },
      
      // Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ Ğ·Ğ²Ğ¾Ğ½ĞºĞ°
      endCall: async () => {
        try {
          const state = get();
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ voiceChannelParticipants Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ ĞºĞ°Ğ½Ğ°Ğ»Ğ°
          if (state.currentRoomId) {
            get().clearVoiceChannelParticipants(state.currentRoomId);
            console.log('ğŸ“¢ Cleared voice channel participants for:', state.currentRoomId);
          }
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹
          voiceCallApi.off('peerJoined');
          voiceCallApi.off('peerLeft');
          voiceCallApi.off('peerMuteStateChanged');
          voiceCallApi.off('peerAudioStateChanged');
          voiceCallApi.off('newProducer');
          voiceCallApi.off('producerClosed');
          voiceCallApi.off('globalAudioStateChanged');
          
          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ socket Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸
          if (voiceCallApi.socket) {
            voiceCallApi.socket.off('globalAudioState');
            voiceCallApi.socket.off('speakingStateChanged');
          }
          
          if (state.localStream) {
            state.localStream.getTracks().forEach(track => track.stop());
          }
          
          // ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° ÑˆÑƒĞ¼Ğ¾Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ
          if (state.noiseSuppressionManager) {
            state.noiseSuppressionManager.cleanup();
          }
          
          // ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ²ÑĞµÑ… Voice Activity Detectors
          get().cleanupAllVAD();
          
          // Ğ—Ğ°ĞºÑ€Ñ‹Ñ‚Ğ¸Ğµ audio context
          if (state.audioContext && state.audioContext.state !== 'closed') {
            await state.audioContext.close();
          }
          
          if (state.sendTransport) {
            state.sendTransport.close();
          }
          
          if (state.recvTransport) {
            state.recvTransport.close();
          }
          
          state.consumers.forEach(consumer => consumer.close());
          state.producers.forEach(producer => producer.close());
          
          // ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° GainNodes Ğ¸ audio elements
          state.gainNodes.forEach(gainNode => {
            try {
              gainNode.disconnect();
            } catch (e) {
              console.warn('Error disconnecting gain node:', e);
            }
          });
          
          state.audioElements.forEach(audioElement => {
            try {
              audioElement.pause();
              audioElement.srcObject = null;
              if (audioElement.parentNode) {
                audioElement.parentNode.removeChild(audioElement);
              }
            } catch (e) {
              console.warn('Error removing audio element:', e);
            }
          });
          
          // Ğ’Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ·Ğ²ÑƒĞº Ğ¾Ñ‚ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ ÑĞ°Ğ¼Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
          audioNotificationManager.playUserLeftSound().catch(error => {
            console.warn('Failed to play user left sound for self:', error);
          });
          
          await voiceCallApi.disconnect();
          
          set({
            isConnected: false,
            isInCall: false,
            currentRoomId: null,
            currentCall: null,
            participants: [],
            participantMuteStates: new Map(),
            participantAudioStates: new Map(),
            participantGlobalAudioStates: new Map(),
            participantVideoStates: new Map(),
            userVolumes: new Map(),
            userMutedStates: new Map(),
            showVolumeSliders: new Map(),
            gainNodes: new Map(),
            audioElements: new Map(),
            previousVolumes: new Map(),
            peerIdToUserIdMap: new Map(),
            device: null,
            sendTransport: null,
            recvTransport: null,
            producers: new Map(),
            consumers: new Map(),
            localStream: null,
            noiseSuppressionManager: null,
            audioContext: null,
            connecting: false
          });
          
          console.log('Call ended successfully');
        } catch (error) {
          console.error('Failed to end call:', error);
          set({ error: error.message });
        }
      },
      
      // Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞºÑ€Ğ°Ğ½Ğ°
      startScreenShare: async () => {
        try {
          const state = get();
          
          // ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²ÑƒÑÑ‰ÑƒÑ Ğ´ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞºÑ€Ğ°Ğ½Ğ°, ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ
          if (state.isScreenSharing) {
            await get().stopScreenShare();
          }

          console.log('Starting screen share via LiveKit...');
          
          // Use LiveKit API to start screen share
          await voiceCallApi.setScreenShareEnabled(true);
          
          // Get the screen share stream from LiveKit room
          const room = voiceCallApi.getRoom();
          if (room) {
            // Listen for local track published event to get the stream
            const handleLocalTrackPublished = (publication) => {
              // Check if it's a screen share track
              const isScreenShare = publication.source === 'screen_share' || 
                                   publication.source === 2; // Track.Source.ScreenShare = 2
              
              if (isScreenShare && publication.track) {
                const stream = new MediaStream([publication.track.mediaStreamTrack]);
                set({ screenShareStream: stream, isScreenSharing: true });
                
                // Handle track ended
                publication.track.on('ended', () => {
                  console.log('Screen sharing stopped by user');
                  get().stopScreenShare();
                });
              }
            };
            
            // Check if screen share track already exists
            room.localParticipant.videoTrackPublications.forEach(publication => {
              const isScreenShare = publication.source === 'screen_share' || 
                                   publication.source === 2;
              if (isScreenShare && publication.track) {
                handleLocalTrackPublished(publication);
              }
            });
            
            // Listen for new screen share tracks
            room.on('LocalTrackPublished', handleLocalTrackPublished);
          }
          
          set({ isScreenSharing: true });

        } catch (error) {
          console.error('Error starting screen share:', error);
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞ²Ğ»ÑĞµÑ‚ÑÑ Ğ»Ğ¸ ÑÑ‚Ğ¾ Ğ¾Ñ‚Ğ¼ĞµĞ½Ğ¾Ğ¹ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼
          const isCancelled = error.message && (
            error.message.includes('Ğ¾Ñ‚Ğ¼ĞµĞ½ĞµĞ½Ğ°') || 
            error.message.includes('cancelled') ||
            error.message.includes('canceled') ||
            error.message.includes('Permission denied') ||
            error.name === 'NotAllowedError' ||
            error.name === 'AbortError'
          );
          
          set({ isScreenSharing: false });
          
          // ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ğ½Ğµ Ğ¾Ñ‚Ğ¼ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼
          if (!isCancelled) {
            set({ error: 'Failed to start screen sharing: ' + error.message });
          } else {
            console.log('Screen sharing cancelled by user');
          }
        }
      },

      stopScreenShare: async () => {
        console.log('Stopping screen sharing...');

        try {
          const state = get();
          
          // Use LiveKit API to stop screen share
          await voiceCallApi.setScreenShareEnabled(false);

          // ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ñ‚Ğ¾Ğº
          if (state.screenShareStream) {
            state.screenShareStream.getTracks().forEach(track => track.stop());
          }

          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
          set({
            screenShareStream: null,
            isScreenSharing: false
          });

          console.log('Screen sharing stopped successfully');
        } catch (error) {
          console.error('Error stopping screen share:', error);
          set({ error: 'Failed to stop screen sharing: ' + error.message });
        }
      },

      toggleScreenShare: async () => {
        console.log('toggleScreenShare called');
        const state = get();
        console.log('Current state:', { isScreenSharing: state.isScreenSharing, sendTransport: !!state.sendTransport });
        if (state.isScreenSharing) {
          console.log('Stopping screen share...');
          await get().stopScreenShare();
          console.log('After stopScreenShare, state:', { 
            isScreenSharing: get().isScreenSharing, 
            screenShareStream: get().screenShareStream 
          });
        } else {
          console.log('Starting screen share...');
          await get().startScreenShare();
        }
      },

      // Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ/Ğ²Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
      toggleVideo: async () => {
        console.log('ğŸ¥ğŸ¥ğŸ¥ toggleVideo called in callStore');
        const state = get();
        console.log('ğŸ¥ Current state:', { isVideoEnabled: state.isVideoEnabled, sendTransport: !!state.sendTransport });
        if (state.isVideoEnabled) {
          console.log('ğŸ¥ Stopping video...');
          await get().stopVideo();
        } else {
          console.log('ğŸ¥ Starting video...');
          await get().startVideo();
        }
      },

      // Ğ’ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
      startVideo: async () => {
        console.log('ğŸ¥ğŸ¥ğŸ¥ startVideo called');
        try {
          const state = get();
          console.log('ğŸ¥ startVideo state check:', { currentUserId: state.currentUserId });

          console.log('Enabling camera via LiveKit...');
          
          // Use LiveKit API to enable camera
          await voiceCallApi.setCameraEnabled(true);
          
          // Get the camera stream from LiveKit room
          const room = voiceCallApi.getRoom();
          if (room) {
            // Listen for local track published event to get the stream
            const handleLocalTrackPublished = (publication) => {
              // Check if it's a camera track
              const isCamera = publication.source === 'camera' || 
                              publication.source === 1; // Track.Source.Camera = 1
              
              if (isCamera && publication.track) {
                const stream = new MediaStream([publication.track.mediaStreamTrack]);
                set({ cameraStream: stream, isVideoEnabled: true });
                
                // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
                set((state) => {
                  const newVideoStates = new Map(state.participantVideoStates);
                  newVideoStates.set(state.currentUserId, true);
                  return { participantVideoStates: newVideoStates };
                });
                
                // Handle track ended
                publication.track.on('ended', () => {
                  console.log('Video track ended');
                  get().stopVideo();
                });
              }
            };
            
            // Check if camera track already exists
            room.localParticipant.videoTrackPublications.forEach(publication => {
              const isCamera = publication.source === 'camera' || 
                              publication.source === 1;
              if (isCamera && publication.track) {
                handleLocalTrackPublished(publication);
              }
            });
            
            // Listen for new camera tracks
            room.on(RoomEvent.LocalTrackPublished, handleLocalTrackPublished);
          }
          
          set({ isVideoEnabled: true });

        } catch (error) {
          console.error('Error starting video:', error);
          set({ error: 'Failed to start video: ' + error.message });
        }
      },

      // Ğ’Ñ‹ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
      stopVideo: async () => {
        console.log('ğŸ¥ğŸ¥ğŸ¥ STOP VIDEO START ğŸ¥ğŸ¥ğŸ¥');
        try {
          const state = get();
        console.log('ğŸ¥ Current state before stop:', {
          isVideoEnabled: state.isVideoEnabled,
          hasVideoProducer: !!state.videoProducer,
          hasCameraStream: !!state.cameraStream,
          hasAudioStream: !!state.audioStream,
          hasLocalStream: !!state.localStream,
          producersCount: state.producers.size,
          producersKeys: Array.from(state.producers.keys())
        });
        
        // ğŸ” Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ¯ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ ĞĞ£Ğ”Ğ˜Ğ Ğ”Ğ ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜ Ğ’Ğ•Ğ‘ĞšĞĞœĞ•Ğ Ğ«
        console.log('ğŸ”ğŸ”ğŸ” ĞĞ£Ğ”Ğ˜Ğ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ Ğ”Ğ ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜ Ğ’Ğ•Ğ‘ĞšĞĞœĞ•Ğ Ğ« ğŸ”ğŸ”ğŸ”');
        
        // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ audio producers Ğ”Ğ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸
        const audioProducersBefore = Array.from(state.producers.values()).filter(p => p.kind === 'audio');
        console.log('ğŸ” Audio producers Ğ”Ğ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹:', audioProducersBefore.length);
        audioProducersBefore.forEach(producer => {
          console.log('ğŸ” Audio producer Ğ”Ğ:', {
            id: producer.id,
            kind: producer.kind,
            closed: producer.closed,
            paused: producer.paused,
            appData: producer.appData
          });
        });
        
        // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ audio consumers Ğ”Ğ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸
        const audioConsumersBefore = Array.from(state.consumers.values()).filter(c => c.kind === 'audio');
        console.log('ğŸ” Audio consumers Ğ”Ğ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹:', audioConsumersBefore.length);
        audioConsumersBefore.forEach(consumer => {
          console.log('ğŸ” Audio consumer Ğ”Ğ:', {
            id: consumer.id,
            kind: consumer.kind,
            closed: consumer.closed,
            paused: consumer.paused,
            producerPaused: consumer.producerPaused,
            producerId: consumer.producer ? consumer.producer.id : 'NO_PRODUCER',
            producerClosed: consumer.producer ? consumer.producer.closed : 'NO_PRODUCER',
            producerPausedState: consumer.producer ? consumer.producer.paused : 'NO_PRODUCER'
          });
        });
          
          // Use LiveKit API to disable camera
          try {
            await voiceCallApi.setCameraEnabled(false);
            console.log('ğŸ¥ Camera disabled via LiveKit');
          } catch (error) {
            console.log('ğŸ¥ stopVideo: setCameraEnabled failed:', error.message);
          }


          // ĞÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹ (Ğ¾Ğ½ ÑĞ¾Ğ´ĞµÑ€Ğ¶Ğ¸Ñ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ‚Ñ€ĞµĞºĞ¸)
          if (state.cameraStream) {
            console.log('ğŸ¥ Stopping camera stream tracks');
            const tracks = state.cameraStream.getTracks();
            console.log('ğŸ¥ Camera stream tracks count:', tracks.length);
            tracks.forEach(track => {
              console.log('ğŸ¥ Stopping camera track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled);
              track.stop();
            });
            console.log('ğŸ¥ Camera stream tracks stopped');
          } else {
            console.log('ğŸ¥ No camera stream to stop');
          }

          // ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹
          console.log('ğŸ¥ Clearing video state...');
          set({
            isVideoEnabled: false,
            videoProducer: null,
            cameraStream: null,
            cameraAudioProducer: null
          });
          
          // ĞĞ±Ğ½Ğ¾Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ²ĞµĞ±-ĞºĞ°Ğ¼ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
          set((state) => {
            const newVideoStates = new Map(state.participantVideoStates);
            newVideoStates.set(state.currentUserId, false);
            return { participantVideoStates: newVideoStates };
          });
          
          console.log('ğŸ¥ Video state cleared');
          
          console.log('ğŸ¥ Video stopped, but audio should continue working');
          
          // ğŸ” Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞĞ¯ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ ĞĞ£Ğ”Ğ˜Ğ ĞŸĞĞ¡Ğ›Ğ• ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜ Ğ’Ğ•Ğ‘ĞšĞĞœĞ•Ğ Ğ«
          console.log('ğŸ”ğŸ”ğŸ” ĞĞ£Ğ”Ğ˜Ğ Ğ”Ğ˜ĞĞ“ĞĞĞ¡Ğ¢Ğ˜ĞšĞ ĞŸĞĞ¡Ğ›Ğ• ĞĞ¡Ğ¢ĞĞĞĞ’ĞšĞ˜ Ğ’Ğ•Ğ‘ĞšĞĞœĞ•Ğ Ğ« ğŸ”ğŸ”ğŸ”');
          
          const currentState = get();
          console.log('ğŸ” Ğ¡Ğ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹:', {
            hasAudioStream: !!currentState.audioStream,
            hasLocalStream: !!currentState.localStream,
            audioStreamTracks: currentState.audioStream ? currentState.audioStream.getTracks().length : 0,
            localStreamTracks: currentState.localStream ? currentState.localStream.getTracks().length : 0,
            producersCount: currentState.producers.size,
            consumersCount: currentState.consumers.size
          });
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ audio producers
          const audioProducers = Array.from(currentState.producers.values()).filter(p => p.kind === 'audio');
          console.log('ğŸ” Audio producers Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹:', audioProducers.length);
          audioProducers.forEach(producer => {
            console.log('ğŸ” Audio producer:', {
              id: producer.id,
              kind: producer.kind,
              closed: producer.closed,
              paused: producer.paused,
              appData: producer.appData
            });
          });
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ audio consumers
          const audioConsumers = Array.from(currentState.consumers.values()).filter(c => c.kind === 'audio');
          console.log('ğŸ” Audio consumers Ğ¿Ğ¾ÑĞ»Ğµ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ¸ Ğ²ĞµĞ±ĞºĞ°Ğ¼ĞµÑ€Ñ‹:', audioConsumers.length);
          audioConsumers.forEach(consumer => {
            console.log('ğŸ” Audio consumer:', {
              id: consumer.id,
              kind: consumer.kind,
              closed: consumer.closed,
              paused: consumer.paused,
              producerPaused: consumer.producerPaused,
              producerId: consumer.producer ? consumer.producer.id : 'NO_PRODUCER',
              producerClosed: consumer.producer ? consumer.producer.closed : 'NO_PRODUCER',
              producerPausedState: consumer.producer ? consumer.producer.paused : 'NO_PRODUCER'
            });
          });
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ñ‡Ñ‚Ğ¾ Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ°ÑƒĞ´Ğ¸Ğ¾ producer Ğ½Ğµ Ğ·Ğ°Ñ‚Ñ€Ğ¾Ğ½ÑƒÑ‚
          console.log('ğŸ¥ Final state after stop:', {
            isVideoEnabled: currentState.isVideoEnabled,
            hasVideoProducer: !!currentState.videoProducer,
            hasCameraStream: !!currentState.cameraStream,
            hasAudioStream: !!currentState.audioStream,
            hasLocalStream: !!currentState.localStream,
            producersCount: currentState.producers.size,
            producersKeys: Array.from(currentState.producers.keys())
          });
          
          console.log('ğŸ¥ Remaining producers after video stop:', Array.from(currentState.producers.keys()));
          console.log('ğŸ¥ Audio context state:', currentState.audioContext?.state);
          console.log('ğŸ¥ Camera stream state:', currentState.cameraStream ? 'exists' : 'null');
          console.log('ğŸ¥ Is video enabled:', currentState.isVideoEnabled);
          
          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ñ‚Ñ€ĞµĞºĞ¸ Ğ² Ğ¾ÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ
          if (currentState.audioStream) {
            const audioTracks = currentState.audioStream.getAudioTracks();
            console.log('ğŸ¥ Main audio stream tracks:', audioTracks.length);
            audioTracks.forEach(track => {
              console.log('ğŸ¥ Main audio track:', track.label, 'enabled:', track.enabled, 'readyState:', track.readyState);
            });
          } else {
            console.log('ğŸ¥ Main audio stream: null');
          }

          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ localStream
          if (currentState.localStream) {
            const localTracks = currentState.localStream.getTracks();
            console.log('ğŸ¥ Local stream tracks:', localTracks.length);
            localTracks.forEach(track => {
              console.log('ğŸ¥ Local track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled, 'readyState:', track.readyState);
            });
          } else {
            console.log('ğŸ¥ Local stream: null');
          }

          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ consumers
          const finalState = get();
          console.log('ğŸ¥ Consumers after video stop:', Array.from(finalState.consumers.keys()));
          console.log('ğŸ¥ Consumers count:', finalState.consumers.size);
          finalState.consumers.forEach((consumer, id) => {
            console.log('ğŸ¥ Consumer:', id, 'kind:', consumer.kind, 'paused:', consumer.paused, 'producerPaused:', consumer.producerPaused, 'closed:', consumer.closed);
            console.log('ğŸ¥ Consumer producer:', consumer.producerId, 'producer closed:', consumer.producer?.closed, 'producer paused:', consumer.producer?.paused);
          });

          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ producers
          console.log('ğŸ¥ Producers after video stop:', Array.from(finalState.producers.keys()));
          console.log('ğŸ¥ Producers count:', finalState.producers.size);
          finalState.producers.forEach((producer, id) => {
            console.log('ğŸ¥ Producer:', id, 'kind:', producer.kind, 'paused:', producer.paused, 'closed:', producer.closed);
          });

          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ audio elements
          console.log('ğŸ¥ Audio elements count:', finalState.audioElements.size);
          finalState.audioElements.forEach((audioElement, userId) => {
            console.log('ğŸ¥ Audio element for user:', userId, 'srcObject:', !!audioElement.srcObject, 'paused:', audioElement.paused, 'muted:', audioElement.muted, 'currentTime:', audioElement.currentTime, 'duration:', audioElement.duration);
            if (audioElement.srcObject) {
              console.log('ğŸ¥ Audio element srcObject tracks:', audioElement.srcObject.getTracks().length);
              audioElement.srcObject.getTracks().forEach(track => {
                console.log('ğŸ¥ Audio track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled, 'readyState:', track.readyState);
              });
            }
          });

          // ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ gain nodes
          console.log('ğŸ¥ Gain nodes count:', finalState.gainNodes.size);
          finalState.gainNodes.forEach((gainNode, userId) => {
            console.log('ğŸ¥ Gain node for user:', userId, 'gain:', gainNode.gain.value, 'context:', gainNode.context.state);
          });

          console.log('ğŸ¥ğŸ¥ğŸ¥ STOP VIDEO END ğŸ¥ğŸ¥ğŸ¥');
          console.log('Video stopped successfully');
        } catch (error) {
          console.error('Error stopping video:', error);
          set({ error: 'Failed to stop video: ' + error.message });
        }
      }
    }),
    {
      name: 'call-store',
    }
  )
);
