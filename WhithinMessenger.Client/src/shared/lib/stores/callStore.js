import { create } from 'zustand';
import { devtools } from 'zustand/middleware';
import { voiceCallApi } from '../../../entities/voice-call/api/voiceCallApi';
import { NoiseSuppressionManager } from '../utils/noiseSuppression';

// ICE ÑÐµÑ€Ð²ÐµÑ€Ñ‹ Ð´Ð»Ñ WebRTC
const ICE_SERVERS = [
  { urls: ['stun:185.119.59.23:3478'] },
  { urls: ['stun:stun.l.google.com:19302'] },
  { urls: ['stun:stun1.l.google.com:19302'] },
  {
    urls: ['turn:185.119.59.23:3478?transport=udp'],
    username: 'test',
    credential: 'test123'
  },
  {
    urls: ['turn:185.119.59.23:3478?transport=tcp'],
    username: 'test',
    credential: 'test123'
  }
];

export const useCallStore = create(
  devtools(
    (set, get) => ({
      // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð·Ð²Ð¾Ð½ÐºÐ°
      isConnected: false,
      isInCall: false,
      currentRoomId: null,
      currentUserId: null,
      currentUserName: null,
      currentCall: null,
      
      // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²
      participants: [],
      peerIdToUserIdMap: new Map(),
      processedProducers: new Set(),
      
      // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾
      isMuted: false,
      isAudioEnabled: true, // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ isAudioEnabled
      isGlobalAudioMuted: false,
      isNoiseSuppressed: false,
      noiseSuppressionMode: 'rnnoise',
      userVolumes: new Map(),
      userMutedStates: new Map(),
      showVolumeSliders: new Map(),
      
      // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
      error: null,
      audioBlocked: false,
      
      // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐºÑ€Ð°Ð½Ð°
      isScreenSharing: false,
      screenShareStream: null,
      remoteScreenShares: new Map(),
      
  // Ð¡Ð¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
  isVideoEnabled: false,
  cameraStream: null, // ÐžÑ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
  videoProducer: null, // Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐºÑ€Ð°Ð½Ð° Ð¾Ñ‚ Ð´Ñ€ÑƒÐ³Ð¸Ñ… Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹ (producerId -> data)
      
      // WebRTC ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ñ (Ñ…Ñ€Ð°Ð½ÑÑ‚ÑÑ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾)
      device: null,
      sendTransport: null,
      recvTransport: null,
      producers: new Map(),
      consumers: new Map(),
      localStream: null,
      noiseSuppressionManager: null,
      audioContext: null,
      gainNodes: new Map(),
      audioElements: new Map(),
      previousVolumes: new Map(),
      
      // Ð¤Ð»Ð°Ð³Ð¸ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
      connecting: false,
      
      // Actions
      setError: (error) => set({ error }),
      clearError: () => set({ error: null }),
      
      setAudioBlocked: (blocked) => set({ audioBlocked: blocked }),
      
      // Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð·Ð²Ð¾Ð½ÐºÐ°
      initializeCall: async (userId, userName) => {
        const state = get();
        if (state.connecting) {
          console.log('Connection already in progress, skipping');
          return;
        }
        
        set({ connecting: true, currentUserId: userId, currentUserName: userName });
        
        try {
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸
          voiceCallApi.off('peerJoined');
          voiceCallApi.off('peerLeft');
          voiceCallApi.off('peerMuteStateChanged');
          voiceCallApi.off('peerAudioStateChanged');
          voiceCallApi.off('newProducer');
          voiceCallApi.off('producerClosed');
          voiceCallApi.off('globalAudioStateChanged');
          
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ socket Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸
          if (voiceCallApi.socket) {
            voiceCallApi.socket.off('globalAudioState');
          }
          
          await voiceCallApi.connect(userId, userName);
          
          // Ð ÐµÐ³Ð¸ÑÑ‚Ñ€Ð¸Ñ€ÑƒÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹
          voiceCallApi.on('peerJoined', (peerData) => {
            console.log('Peer joined:', peerData);
            const socketId = peerData.peerId || peerData.id;
            if (socketId && peerData.userId) {
              const newMap = new Map(get().peerIdToUserIdMap);
              newMap.set(socketId, peerData.userId);
              set({ peerIdToUserIdMap: newMap });
            }
            
            set((state) => ({
              participants: [...state.participants.filter(p => p.userId !== peerData.userId), {
                userId: peerData.userId,
                peerId: socketId,
                name: peerData.name,
                isMuted: peerData.isMuted || false,
                isAudioEnabled: peerData.isAudioEnabled !== undefined ? peerData.isAudioEnabled : true,
                isGlobalAudioMuted: peerData.isGlobalAudioMuted || false, // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð²ÑƒÐºÐ°
                isSpeaking: false
              }]
            }));
          });

          voiceCallApi.on('peerLeft', (peerData) => {
            console.log('Peer left:', peerData);
            const socketId = peerData.peerId || peerData.id;
            const userId = peerData.userId || get().peerIdToUserIdMap.get(socketId);
            
            if (userId) {
              // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ audio element
              const audioElement = get().audioElements.get(userId);
              if (audioElement) {
                audioElement.pause();
                audioElement.srcObject = null;
                if (audioElement.parentNode) {
                  audioElement.parentNode.removeChild(audioElement);
                }
              }
              
              // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ gain node
              const gainNode = get().gainNodes.get(userId);
              if (gainNode) {
                try {
                  gainNode.disconnect();
                } catch (e) {
                  console.warn('Error disconnecting gain node:', e);
                }
              }
              
              // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ
              set((state) => {
                const newUserVolumes = new Map(state.userVolumes);
                const newUserMutedStates = new Map(state.userMutedStates);
                const newShowVolumeSliders = new Map(state.showVolumeSliders);
                const newGainNodes = new Map(state.gainNodes);
                const newAudioElements = new Map(state.audioElements);
                const newPreviousVolumes = new Map(state.previousVolumes);
                const newPeerIdToUserIdMap = new Map(state.peerIdToUserIdMap);
                
                newUserVolumes.delete(userId);
                newUserMutedStates.delete(userId);
                newShowVolumeSliders.delete(userId);
                newGainNodes.delete(userId);
                newAudioElements.delete(userId);
                newPreviousVolumes.delete(userId);
                newPeerIdToUserIdMap.delete(socketId);
                
                return {
                  userVolumes: newUserVolumes,
                  userMutedStates: newUserMutedStates,
                  showVolumeSliders: newShowVolumeSliders,
                  gainNodes: newGainNodes,
                  audioElements: newAudioElements,
                  previousVolumes: newPreviousVolumes,
                  peerIdToUserIdMap: newPeerIdToUserIdMap,
                  participants: state.participants.filter(p => p.userId !== userId)
                };
              });
            }
          });

          voiceCallApi.on('peerMuteStateChanged', ({ peerId, isMuted }) => {
            const userId = get().peerIdToUserIdMap.get(peerId) || peerId;
            set((state) => ({
              participants: state.participants.map(p => 
                p.userId === userId ? { ...p, isMuted: Boolean(isMuted), isSpeaking: isMuted ? false : p.isSpeaking } : p
              )
            }));
          });

          voiceCallApi.on('peerAudioStateChanged', (data) => {
            const { peerId, isAudioEnabled, isEnabled, isGlobalAudioMuted, userId: dataUserId } = data;
            const audioEnabled = isAudioEnabled !== undefined ? isAudioEnabled : isEnabled;
            const userId = dataUserId || get().peerIdToUserIdMap.get(peerId) || peerId;
            
            console.log('peerAudioStateChanged received:', { peerId, userId, isAudioEnabled: audioEnabled, isGlobalAudioMuted });
            console.log('Full data received:', data);
            
            set((state) => ({
              participants: state.participants.map(p => {
                if (p.userId === userId) {
                  const updated = { ...p, isAudioEnabled: Boolean(audioEnabled) };
                  // Ð•ÑÐ»Ð¸ ÑÐµÑ€Ð²ÐµÑ€ Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÑ‚ isGlobalAudioMuted, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ ÐµÐ³Ð¾
                  if (isGlobalAudioMuted !== undefined) {
                    updated.isGlobalAudioMuted = isGlobalAudioMuted;
                    console.log('Updated participant with global audio state:', updated);
                  } else {
                    console.log('isGlobalAudioMuted not provided by server, keeping existing state');
                    // ÐÐµ Ð¸Ð·Ð¼ÐµÐ½ÑÐµÐ¼ isGlobalAudioMuted, ÐµÑÐ»Ð¸ ÑÐµÑ€Ð²ÐµÑ€ ÐµÐ³Ð¾ Ð½Ðµ Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÑ‚
                  }
                  return updated;
                }
                return p;
              })
            }));
          });

          voiceCallApi.on('newProducer', async (producerData) => {
            const state = get();
            if (state.device && state.recvTransport) {
              await state.handleNewProducer(producerData);
            }
          });

          voiceCallApi.on('producerClosed', (data) => {
            console.log('ðŸŽ¥ Producer closed event received:', data);
            
            const producerId = data.producerId || data;
            const producerSocketId = data.producerSocketId;
            const producerKind = data.kind; // video Ð¸Ð»Ð¸ audio
            const mediaType = data.mediaType; // screen Ð¸Ð»Ð¸ camera
            
            console.log('ðŸŽ¥ Producer closed parsed:', { producerId, producerSocketId, producerKind, mediaType });
            
            // Ð—Ð°Ñ‰Ð¸Ñ‚Ð° Ð¾Ñ‚ Ð´ÑƒÐ±Ð»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            const state = get();
            if (state.processedProducers && state.processedProducers.has(producerId)) {
              console.log('ðŸŽ¥ Producer already processed, ignoring:', producerId);
              return;
            }
            
            // ÐžÑ‚Ð¼ÐµÑ‡Ð°ÐµÐ¼ producer ÐºÐ°Ðº Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹
            set(state => ({
              processedProducers: new Set([...(state.processedProducers || []), producerId])
            }));
            
            // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÑ‚Ð¾ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹ ÑÐºÑ€Ð°Ð½Ð°
            const screenShare = state.remoteScreenShares.get(producerId);
            if (screenShare) {
              console.log('Screen share producer closed:', producerId);
              // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº
              if (screenShare.stream) {
                screenShare.stream.getTracks().forEach(track => track.stop());
              }
              // Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð¸Ð· Map
              const newRemoteScreenShares = new Map(state.remoteScreenShares);
              newRemoteScreenShares.delete(producerId);
              set({ remoteScreenShares: newRemoteScreenShares });
            }
            
            // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÑ‚Ð¾ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ð¾Ð¹ (video producer Ñ mediaType camera)
            const userId = state.peerIdToUserIdMap.get(producerSocketId) || producerSocketId;
            
            // Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ð°ÑƒÐ´Ð¸Ð¾ producer, Ð½Ðµ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÐµÐ³Ð¾ Ð·Ð´ÐµÑÑŒ
            if (producerKind === 'audio' && mediaType !== 'screen') {
              console.log('ðŸŽ¥ Audio producer closed, ignoring to preserve audio stream');
              return;
            }
            
            // Ð•ÑÐ»Ð¸ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹ kind Ð¸ mediaType Ð½Ðµ Ð¿Ñ€Ð¸Ñ…Ð¾Ð´ÑÑ‚, Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð¿Ð¾ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°Ð¼
            let isVideoProducer = false;
            if (producerKind === 'video' && mediaType === 'camera') {
              isVideoProducer = true;
            } else if (mediaType === 'camera') {
              // Ð•ÑÐ»Ð¸ mediaType === 'camera', Ñ‚Ð¾ ÑÑ‚Ð¾ Ñ‚Ð¾Ñ‡Ð½Ð¾ video producer
              console.log('ðŸŽ¥ Detected video producer by mediaType:', userId);
              isVideoProducer = true;
            } else if (!producerKind && !mediaType) {
              // ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ°: ÐµÑÐ»Ð¸ Ñƒ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ° ÐµÑÑ‚ÑŒ isVideoEnabled, Ñ‚Ð¾ ÑÑ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ video producer
              const participant = state.participants.find(p => p.userId === userId);
              if (participant && participant.isVideoEnabled) {
                console.log('ðŸŽ¥ Detected video producer by participant state:', userId);
                isVideoProducer = true;
              }
            }
            
            if (userId && userId !== state.currentUserId && isVideoProducer) {
              console.log('ðŸŽ¥ Camera video producer closed for user:', userId);
              // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ° - Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñƒ
              set((state) => {
                const updatedParticipants = state.participants.map(p => 
                  p.userId === userId 
                    ? { ...p, isVideoEnabled: false, videoStream: null }
                    : p
                );
                console.log('ðŸŽ¥ Updated participants after video close:', updatedParticipants);
                return { participants: updatedParticipants };
              });
            }
            
            // Ð£Ð´Ð°Ð»ÑÐµÐ¼ consumer Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ video producer, Ð½Ðµ Ð´Ð»Ñ audio
            if (isVideoProducer || mediaType === 'screen') {
              const consumer = get().consumers.get(producerId);
              if (consumer) {
                console.log('ðŸŽ¥ Closing consumer for video producer:', producerId, 'kind:', consumer.kind);
                consumer.close();
                set((state) => {
                  const newConsumers = new Map(state.consumers);
                  newConsumers.delete(producerId);
                  return { consumers: newConsumers };
                });
              } else {
                console.log('ðŸŽ¥ No consumer found for video producer:', producerId);
              }
            } else {
              console.log('ðŸŽ¥ Preserving consumer for audio producer:', producerId);
              const consumer = get().consumers.get(producerId);
              if (consumer) {
                console.log('ðŸŽ¥ Audio consumer preserved:', producerId, 'kind:', consumer.kind, 'paused:', consumer.paused);
              } else {
                console.log('ðŸŽ¥ No audio consumer found for producer:', producerId);
              }
            }
            
            if (producerSocketId) {
              const userId = get().peerIdToUserIdMap.get(producerSocketId);
              if (userId) {
                // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ audio element Ð¸ gain node
                const audioElement = get().audioElements.get(userId);
                if (audioElement) {
                  audioElement.pause();
                  audioElement.srcObject = null;
                  if (audioElement.parentNode) {
                    audioElement.parentNode.removeChild(audioElement);
                  }
                }
                
                const gainNode = get().gainNodes.get(userId);
                if (gainNode) {
                  try {
                    gainNode.disconnect();
                  } catch (e) {
                    console.warn('Error disconnecting gain node:', e);
                  }
                }
                
                set((state) => {
                  const newUserVolumes = new Map(state.userVolumes);
                  const newUserMutedStates = new Map(state.userMutedStates);
                  const newShowVolumeSliders = new Map(state.showVolumeSliders);
                  const newGainNodes = new Map(state.gainNodes);
                  const newAudioElements = new Map(state.audioElements);
                  const newPreviousVolumes = new Map(state.previousVolumes);
                  
                  newUserVolumes.delete(userId);
                  newUserMutedStates.delete(userId);
                  newShowVolumeSliders.delete(userId);
                  newGainNodes.delete(userId);
                  newAudioElements.delete(userId);
                  newPreviousVolumes.delete(userId);
                  
                  return {
                    userVolumes: newUserVolumes,
                    userMutedStates: newUserMutedStates,
                    showVolumeSliders: newShowVolumeSliders,
                    gainNodes: newGainNodes,
                    audioElements: newAudioElements,
                    previousVolumes: newPreviousVolumes
                  };
                });
              }
            }
          });

          // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð´Ð»Ñ ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¸ ÑÑ‚Ð°Ñ‚ÑƒÑÐ° Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð²ÑƒÐºÐ°
          voiceCallApi.on('globalAudioStateChanged', (data) => {
            const { userId, isGlobalAudioMuted } = data;
            console.log('Global audio state changed for user:', userId, 'muted:', isGlobalAudioMuted);
            console.log('Current participants before update:', get().participants);
            
            set((state) => {
              const updatedParticipants = state.participants.map(p => 
                p.userId === userId ? { ...p, isGlobalAudioMuted } : p
              );
              console.log('Updated participants:', updatedParticipants);
              return { participants: updatedParticipants };
            });
          });

          // Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ðµ Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ: ÑÐ»ÑƒÑˆÐ°ÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ globalAudioState Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð°
          if (voiceCallApi.socket) {
            voiceCallApi.socket.on('globalAudioState', (data) => {
              console.log('Received globalAudioState from server:', data);
              const { userId, isGlobalAudioMuted } = data;
              
              set((state) => {
                const updatedParticipants = state.participants.map(p => 
                  p.userId === userId ? { ...p, isGlobalAudioMuted } : p
                );
                console.log('Updated participants with globalAudioState:', updatedParticipants);
                return { participants: updatedParticipants };
              });
            });
          }
          
          set({ isConnected: true, connecting: false, processedProducers: new Set() });
          
          // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ðµ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€
          if (voiceCallApi.socket) {
            voiceCallApi.socket.emit('muteState', { isMuted: get().isMuted });
            voiceCallApi.socket.emit('audioState', { isEnabled: !get().isGlobalAudioMuted });
          }
        } catch (error) {
          console.error('Failed to initialize call:', error);
          set({ error: error.message, connecting: false });
        }
      },
      
      // ÐŸÑ€Ð¸ÑÐ¾ÐµÐ´Ð¸Ð½ÐµÐ½Ð¸Ðµ Ðº ÐºÐ¾Ð¼Ð½Ð°Ñ‚Ðµ
      joinRoom: async (roomId) => {
        const state = get();
        if (!state.isConnected) {
          console.error('Not connected to voice server');
          return;
        }
        
        try {
          console.log('Joining room:', roomId);
          const response = await voiceCallApi.joinRoom(roomId, state.currentUserName, state.currentUserId);
          
          if (response.routerRtpCapabilities) {
            await state.initializeDevice(response.routerRtpCapabilities);
          }
          
          if (response.existingPeers) {
            // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³ Ð´Ð»Ñ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰Ð¸Ñ… Ð¿Ð¸Ñ€Ð¾Ð²
            const newMap = new Map(state.peerIdToUserIdMap);
            response.existingPeers.forEach(peer => {
              const socketId = peer.peerId || peer.id;
              if (socketId && peer.userId) {
                newMap.set(socketId, peer.userId);
              }
            });
            
            set({
              peerIdToUserIdMap: newMap,
              participants: response.existingPeers.map(peer => ({
                userId: peer.userId,
                peerId: peer.peerId || peer.id,
                name: peer.name,
                isMuted: peer.isMuted || false,
                isAudioEnabled: peer.isAudioEnabled !== undefined ? peer.isAudioEnabled : true,
                isGlobalAudioMuted: peer.isGlobalAudioMuted || false, // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑÑ‚Ð°Ñ‚ÑƒÑ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð²ÑƒÐºÐ°
                isSpeaking: false
              }))
            });
          }
          
          if (response.existingProducers && response.existingProducers.length > 0) {
            for (const producer of response.existingProducers) {
              try {
                await state.handleNewProducer(producer);
              } catch (error) {
                console.error('Failed to process existing producer:', error);
              }
            }
          }
          
          // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾Ðº
          await state.createAudioStream();
          
          set({ currentRoomId: roomId, isInCall: true, currentCall: { channelId: roomId, channelName: roomId } });
        } catch (error) {
          console.error('Failed to join room:', error);
          set({ error: error.message });
        }
      },
      
      // Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑƒÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð°
      initializeDevice: async (routerRtpCapabilities) => {
        try {
          const device = await voiceCallApi.initializeDevice(routerRtpCapabilities);
          set({ device });
          await get().createTransports();
        } catch (error) {
          console.error('Failed to initialize device:', error);
          set({ error: error.message });
        }
      },
      
      // Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ñ‚Ñ€Ð°Ð½ÑÐ¿Ð¾Ñ€Ñ‚Ð¾Ð²
      createTransports: async () => {
        try {
          const state = get();
          if (!state.device) return;
          
          // Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ send transport
          const sendTransportData = await voiceCallApi.createWebRtcTransport();
          const sendTransport = state.device.createSendTransport({
            id: sendTransportData.id,
            iceParameters: sendTransportData.iceParameters,
            iceCandidates: sendTransportData.iceCandidates,
            dtlsParameters: sendTransportData.dtlsParameters,
            iceServers: ICE_SERVERS
          });

          sendTransport.on('connect', async ({ dtlsParameters }, callback, errback) => {
            try {
              await voiceCallApi.connectTransport(sendTransportData.id, dtlsParameters);
              callback();
            } catch (error) {
              errback(error);
            }
          });

          sendTransport.on('produce', async ({ kind, rtpParameters, appData }, callback, errback) => {
            try {
              const { id } = await voiceCallApi.produce(sendTransportData.id, kind, rtpParameters, appData);
              callback({ id });
            } catch (error) {
              errback(error);
            }
          });

          // Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ recv transport
          const recvTransportData = await voiceCallApi.createWebRtcTransport();
          const recvTransport = state.device.createRecvTransport({
            id: recvTransportData.id,
            iceParameters: recvTransportData.iceParameters,
            iceCandidates: recvTransportData.iceCandidates,
            dtlsParameters: recvTransportData.dtlsParameters,
            iceServers: ICE_SERVERS
          });

          recvTransport.on('connect', async ({ dtlsParameters }, callback, errback) => {
            try {
              await voiceCallApi.connectTransport(recvTransportData.id, dtlsParameters);
              callback();
            } catch (error) {
              errback(error);
            }
          });

          set({ sendTransport, recvTransport });
          console.log('Transports created');
        } catch (error) {
          console.error('Failed to create transports:', error);
          set({ error: error.message });
        }
      },
      
      // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð½Ð¾Ð²Ð¾Ð³Ð¾ producer
      handleNewProducer: async (producerData) => {
        try {
          const state = get();
          if (!state.device || !state.recvTransport) return;
          
          const consumerData = await voiceCallApi.consume(
            state.device.rtpCapabilities,
            producerData.producerId,
            state.recvTransport.id
          );

          const consumer = await state.recvTransport.consume({
            id: consumerData.id,
            producerId: producerData.producerId,
            kind: producerData.kind,
            rtpParameters: consumerData.rtpParameters
          });

          set((state) => {
            const newConsumers = new Map(state.consumers);
            newConsumers.set(consumerData.id, consumer);
            return { consumers: newConsumers };
          });
          
          const socketId = producerData.producerSocketId;
          const userId = state.peerIdToUserIdMap.get(socketId) || socketId;
          
          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ ÑÑ‚Ð¾ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹ ÑÐºÑ€Ð°Ð½Ð°
          const isScreenShare = producerData.appData?.mediaType === 'screen';
          console.log('callStore handleNewProducer: isScreenShare=', isScreenShare, 'kind=', producerData.kind, 'userId=', userId, 'currentUserId=', state.currentUserId, 'producerUserId=', producerData.appData?.userId);
          
          // Ð”Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐºÑ€Ð°Ð½Ð° Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ video Ð¸ audio Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾
          if (isScreenShare) {
            // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÑ‚Ð¾ Ð½Ðµ Ð½Ð°ÑˆÐ° ÑÐ¾Ð±ÑÑ‚Ð²ÐµÐ½Ð½Ð°Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐºÑ€Ð°Ð½Ð°
            const producerUserId = producerData.appData?.userId;
            if (producerUserId === state.currentUserId) {
              console.log('Skipping own screen share producer in handleNewProducer', { userId, currentUserId: state.currentUserId, producerUserId });
              return;
            }
            
            console.log('Screen share producer detected in callStore:', { kind: producerData.kind, userId });
            
            if (producerData.kind === 'video') {
              // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ MediaStream Ð¸Ð· consumer track Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ
              const screenStream = new MediaStream([consumer.track]);
              
              const currentState = get();
              const newRemoteScreenShares = new Map(currentState.remoteScreenShares);
              newRemoteScreenShares.set(producerData.producerId, {
                stream: screenStream,
                producerId: producerData.producerId,
                userId: userId,
                userName: producerData.appData?.userName || 'Unknown',
                socketId: socketId
              });
              
              set({ remoteScreenShares: newRemoteScreenShares });
            } else if (producerData.kind === 'audio') {
              console.log('Screen share audio producer detected, creating audio element');
              
              // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ audio element Ð´Ð»Ñ screen share audio
              const audioElement = document.createElement('audio');
              audioElement.srcObject = new MediaStream([consumer.track]);
              audioElement.autoplay = true;
              audioElement.volume = 1.0; // ÐŸÐ¾Ð»Ð½Ð°Ñ Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ Ð´Ð»Ñ screen share audio
              audioElement.muted = false;
              audioElement.playsInline = true;
              audioElement.controls = false;
              audioElement.style.display = 'none';
              
              // Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² DOM Ð´Ð»Ñ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ
              document.body.appendChild(audioElement);
              
              // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ audio element Ð´Ð»Ñ screen share audio
              const screenShareAudioKey = `screen-share-audio-${userId}`;
              const currentState = get();
              const newAudioElements = new Map(currentState.audioElements);
              newAudioElements.set(screenShareAudioKey, audioElement);
              
              set({ audioElements: newAudioElements });
              
              console.log('Screen share audio element created:', screenShareAudioKey);
            }
            
            return;
          }

          // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° video producers (Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ð°)
          if (producerData.kind === 'video' && producerData.appData?.mediaType === 'camera') {
            console.log('ðŸŽ¥ Camera video producer detected, updating participant video stream');
            console.log('ðŸŽ¥ Producer data:', { userId, producerUserId: producerData.appData?.userId, currentUserId: state.currentUserId });
            
            // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ ÑƒÐ¶Ðµ videoStream Ñƒ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ°
            const existingParticipant = state.participants.find(p => p.userId === userId);
            if (existingParticipant && existingParticipant.videoStream) {
              console.log('ðŸŽ¥ Participant already has video stream, skipping creation');
              return;
            }
            
            // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ MediaStream Ð¸Ð· consumer track
            const videoStream = new MediaStream([consumer.track]);
            console.log('ðŸŽ¥ Created video stream:', videoStream);
            
            // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ° Ñ video stream
            set((state) => {
              const updatedParticipants = state.participants.map(p => 
                p.userId === userId 
                  ? { ...p, isVideoEnabled: true, videoStream: videoStream }
                  : p
              );
              console.log('ðŸŽ¥ Updated participants:', updatedParticipants);
              return { participants: updatedParticipants };
            });
            
            return;
          }
          
          // Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÐ¼ AudioContext ÐµÑÐ»Ð¸ ÐµÑ‰Ðµ Ð½Ðµ ÑÐ¾Ð·Ð´Ð°Ð½
          let audioContext = state.audioContext;
          if (!audioContext || audioContext.state === 'closed') {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 48000,
              latencyHint: 'interactive'
            });
            set({ audioContext });
          }
          
          if (audioContext.state === 'suspended') {
            await audioContext.resume();
          }
          
          // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ audio element
          const audioElement = document.createElement('audio');
          audioElement.srcObject = new MediaStream([consumer.track]);
          audioElement.autoplay = true;
          audioElement.playsInline = true;
          audioElement.controls = false;
          audioElement.style.display = 'none';
          document.body.appendChild(audioElement);
          
          // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Web Audio API chain
          const source = audioContext.createMediaStreamSource(new MediaStream([consumer.track]));
          const gainNode = audioContext.createGain();
          source.connect(gainNode);
          
          // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚ÑŒ
          const initialVolume = state.userVolumes.get(userId) || 100;
          const isMuted = state.userMutedStates.get(userId) || false;
          const audioVolume = state.isGlobalAudioMuted ? 0 : (isMuted ? 0 : (initialVolume / 100.0));
          audioElement.volume = audioVolume;
          
          // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑÑ‹Ð»ÐºÐ¸
          set((state) => {
            const newGainNodes = new Map(state.gainNodes);
            const newAudioElements = new Map(state.audioElements);
            newGainNodes.set(userId, gainNode);
            newAudioElements.set(userId, audioElement);
            
            const newUserVolumes = new Map(state.userVolumes);
            if (!newUserVolumes.has(userId)) {
              newUserVolumes.set(userId, 100);
            }
            
            return {
              gainNodes: newGainNodes,
              audioElements: newAudioElements,
              userVolumes: newUserVolumes
            };
          });

          try {
            await audioElement.play();
            console.log('Audio playback started for peer:', userId);
            set({ audioBlocked: false });
          } catch (error) {
            console.log('Auto-play blocked, user interaction required:', error);
            set({ audioBlocked: true });
            setTimeout(async () => {
              try {
                await audioElement.play();
                set({ audioBlocked: false });
              } catch {
                console.log('Audio playback still blocked');
              }
            }, 1000);
          }

          await voiceCallApi.resumeConsumer(consumerData.id);
          console.log('New consumer created:', consumerData.id);
        } catch (error) {
          console.error('Failed to handle new producer:', error);
        }
      },
      
      // Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°
      createAudioStream: async () => {
        try {
          const state = get();
          if (!state.sendTransport) return;
          
          // Ð—Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ðµ producers
          if (state.producers.size > 0) {
            state.producers.forEach(producer => {
              try {
                producer.close();
              } catch (e) {
                console.warn('Error closing producer:', e);
              }
            });
            set({ producers: new Map() });
          }
          
          // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
          if (state.localStream) {
            state.localStream.getTracks().forEach(track => track.stop());
          }
          
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ€Ð¾Ðµ ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ
          if (state.noiseSuppressionManager) {
            state.noiseSuppressionManager.cleanup();
          }
          
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
              sampleRate: 48000,
              channelCount: 1,
              latency: 0,
              suppressLocalAudioPlayback: true
            }
          });

          set({ localStream: stream, audioStream: stream });
          
          // Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ audio context
          let audioContext = state.audioContext;
          if (!audioContext || audioContext.state === 'closed') {
            audioContext = new (window.AudioContext || window.webkitAudioContext)({
              sampleRate: 48000,
              latencyHint: 'interactive'
            });
            set({ audioContext });
          }
          
          if (audioContext.state === 'suspended') {
            await audioContext.resume();
          }
          
          // Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
          const noiseSuppressionManager = new NoiseSuppressionManager();
          await noiseSuppressionManager.initialize(stream, audioContext);
          set({ noiseSuppressionManager });
          
          // ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ‚Ð¾Ðº
          const processedStream = noiseSuppressionManager.getProcessedStream();
          const audioTrack = processedStream.getAudioTracks()[0];
          
          if (!audioTrack) {
            throw new Error('No audio track in processed stream');
          }
          
          // ÐŸÑ€Ð¸Ð¼ÐµÐ½ÑÐµÐ¼ ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ ÐµÑÐ»Ð¸ Ð¾Ð½Ð¾ Ð±Ñ‹Ð»Ð¾ Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¾
          if (state.isNoiseSuppressed) {
            await noiseSuppressionManager.enable(state.noiseSuppressionMode);
          }
          
          // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
          audioTrack.enabled = !state.isMuted;
          
          const producer = await state.sendTransport.produce({
            track: audioTrack,
            appData: { userId: state.currentUserId, userName: state.currentUserName }
          });

          set((state) => {
            const newProducers = new Map(state.producers);
            newProducers.set(producer.id, producer);
            return { producers: newProducers };
          });
          
          // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ producer Ð² noise suppression manager
          noiseSuppressionManager.setProducer(producer);
          
          console.log('Audio stream created with noise suppression support');
          return producer;
        } catch (error) {
          console.error('Failed to create audio stream:', error);
          set({ error: error.message });
        }
      },
      
      // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð°
      toggleMute: () => {
        const state = get();
        const newMutedState = !state.isMuted;
        
        if (state.noiseSuppressionManager) {
          const processedStream = state.noiseSuppressionManager.getProcessedStream();
          const audioTrack = processedStream?.getAudioTracks()[0];
          if (audioTrack) {
            audioTrack.enabled = !newMutedState;
          }
        } else if (state.localStream) {
          const audioTrack = state.localStream.getAudioTracks()[0];
          if (audioTrack) {
            audioTrack.enabled = !newMutedState;
          }
        }
        
        // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼ÑƒÑ‚Ð° Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€
        if (voiceCallApi.socket) {
          voiceCallApi.socket.emit('muteState', { isMuted: newMutedState });
        }
        
        set({ isMuted: newMutedState });
      },
      
      // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¼ÑƒÑ‚Ð° Ð´Ð»Ñ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
      toggleUserMute: (peerId) => {
        const state = get();
        const audioElement = state.audioElements.get(peerId);
        if (!audioElement) return;

        const isCurrentlyMuted = state.userMutedStates.get(peerId) || false;
        const newIsMuted = !isCurrentlyMuted;

        if (newIsMuted) {
          const currentVolume = state.userVolumes.get(peerId) || 100;
          set((state) => {
            const newPreviousVolumes = new Map(state.previousVolumes);
            newPreviousVolumes.set(peerId, currentVolume);
            return { previousVolumes: newPreviousVolumes };
          });
          audioElement.volume = 0;
        } else {
          const currentVolume = state.userVolumes.get(peerId) || 100;
          const audioVolume = state.isGlobalAudioMuted ? 0 : (currentVolume / 100.0);
          audioElement.volume = audioVolume;
        }

        set((state) => {
          const newUserMutedStates = new Map(state.userMutedStates);
          newUserMutedStates.set(peerId, newIsMuted);
          return { userMutedStates: newUserMutedStates };
        });
      },
      
      // Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚Ð¸ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
      changeUserVolume: (peerId, newVolume) => {
        const state = get();
        const audioElement = state.audioElements.get(peerId);
        if (!audioElement) return;

        const audioVolume = state.isGlobalAudioMuted ? 0 : (newVolume / 100.0);
        audioElement.volume = audioVolume;

        set((state) => {
          const newUserVolumes = new Map(state.userVolumes);
          newUserVolumes.set(peerId, newVolume);
          return { userVolumes: newUserVolumes };
        });

        // Ð•ÑÐ»Ð¸ Ñ€Ð°Ð·Ð¼ÑƒÑ‚Ð¸Ð²Ð°ÐµÐ¼ Ñ‡ÐµÑ€ÐµÐ· ÑÐ»Ð°Ð¹Ð´ÐµÑ€, Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼ÑƒÑ‚Ð°
        if (newVolume > 0 && state.userMutedStates.get(peerId)) {
          set((state) => {
            const newUserMutedStates = new Map(state.userMutedStates);
            newUserMutedStates.set(peerId, false);
            return { userMutedStates: newUserMutedStates };
          });
        } else if (newVolume === 0 && !state.userMutedStates.get(peerId)) {
          set((state) => {
            const newUserMutedStates = new Map(state.userMutedStates);
            newUserMutedStates.set(peerId, true);
            return { userMutedStates: newUserMutedStates };
          });
        }
      },
      
      // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ ÑÐ»Ð°Ð¹Ð´ÐµÑ€Ð° Ð³Ñ€Ð¾Ð¼ÐºÐ¾ÑÑ‚Ð¸
      toggleVolumeSlider: (peerId) => {
        set((state) => {
          const newShowVolumeSliders = new Map(state.showVolumeSliders);
          const currentState = newShowVolumeSliders.get(peerId) || false;
          newShowVolumeSliders.set(peerId, !currentState);
          return { showVolumeSliders: newShowVolumeSliders };
        });
      },
      
      // Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ/Ð²ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð·Ð²ÑƒÐºÐ° Ð²ÑÐµÑ… ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²
      toggleGlobalAudio: () => {
        const state = get();
        const newMutedState = !state.isGlobalAudioMuted;
        
        // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð½Ð°ÑƒÑˆÐ½Ð¸ÐºÐ¾Ð² Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€ (ÐºÐ°Ðº Ð² ÑÑ‚Ð°Ñ€Ð¾Ð¼ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ðµ)
        if (voiceCallApi.socket) {
          const audioStateData = { 
            isEnabled: !newMutedState,
            isGlobalAudioMuted: newMutedState,
            userId: get().currentUserId
          };
          console.log('Sending audioState to server:', audioStateData);
          voiceCallApi.socket.emit('audioState', audioStateData);
        }
        
        // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ isAudioEnabled Ð² ÑÐ¾Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ñ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¼ Ð·Ð²ÑƒÐºÐ¾Ð¼
        set({ isGlobalAudioMuted: newMutedState, isAudioEnabled: !newMutedState });
        
        // Ð¢Ð°ÐºÐ¶Ðµ Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð² ÑÐ¿Ð¸ÑÐºÐµ ÑƒÑ‡Ð°ÑÑ‚Ð½Ð¸ÐºÐ¾Ð²
        set((state) => ({
          participants: state.participants.map(p => {
            if (p.userId === state.currentUserId) {
              return { ...p, isGlobalAudioMuted: newMutedState, isAudioEnabled: !newMutedState };
            }
            return p;
          })
        }));
        
        // Ð¢Ð°ÐºÐ¶Ðµ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð´Ð»Ñ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð·Ð²ÑƒÐºÐ°
        if (voiceCallApi.socket) {
          console.log('Sending globalAudioState to server:', { 
            userId: state.currentUserId,
            isGlobalAudioMuted: newMutedState 
          });
          voiceCallApi.socket.emit('globalAudioState', { 
            userId: state.currentUserId,
            isGlobalAudioMuted: newMutedState 
          });
        }
        
        // Ð£Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ HTML Audio ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸
        state.audioElements.forEach((audioElement, peerId) => {
          if (audioElement) {
            if (newMutedState) {
              audioElement.volume = 0;
            } else {
              const volume = state.userVolumes.get(peerId) || 100;
              const isIndividuallyMuted = state.userMutedStates.get(peerId) || false;
              const audioVolume = isIndividuallyMuted ? 0 : (volume / 100.0);
              audioElement.volume = audioVolume;
            }
          }
        });
      },
      
      // ÐŸÐµÑ€ÐµÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
      toggleNoiseSuppression: async () => {
        try {
          const state = get();
          if (!state.noiseSuppressionManager || !state.noiseSuppressionManager.isInitialized()) {
            console.error('Noise suppression not initialized');
            return false;
          }

          const newState = !state.isNoiseSuppressed;
          let success = false;

          if (newState) {
            success = await state.noiseSuppressionManager.enable(state.noiseSuppressionMode);
          } else {
            success = await state.noiseSuppressionManager.disable();
          }

          if (success) {
            set({ isNoiseSuppressed: newState });
            localStorage.setItem('noiseSuppression', JSON.stringify(newState));
            
            // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÐµÐºÐ°
            if (state.noiseSuppressionManager) {
              const processedStream = state.noiseSuppressionManager.getProcessedStream();
              const audioTrack = processedStream?.getAudioTracks()[0];
              if (audioTrack) {
                audioTrack.enabled = !state.isMuted;
              }
            }
            
            return true;
          }
          
          return false;
        } catch (error) {
          console.error('Error toggling noise suppression:', error);
          return false;
        }
      },
      
      // Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ðµ Ñ€ÐµÐ¶Ð¸Ð¼Ð° ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
      changeNoiseSuppressionMode: async (mode) => {
        try {
          const state = get();
          if (!state.noiseSuppressionManager || !state.noiseSuppressionManager.isInitialized()) {
            console.error('Noise suppression not initialized');
            return false;
          }

          let success = false;

          if (!state.isNoiseSuppressed) {
            success = await state.noiseSuppressionManager.enable(mode);
          } else if (mode !== state.noiseSuppressionMode) {
            success = await state.noiseSuppressionManager.enable(mode);
          } else {
            return true; // Ð ÐµÐ¶Ð¸Ð¼ ÑƒÐ¶Ðµ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½
          }

          if (success) {
            set({ noiseSuppressionMode: mode, isNoiseSuppressed: true });
            localStorage.setItem('noiseSuppression', JSON.stringify(true));
            
            // ÐžÐ±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½Ð° Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ‚Ñ€ÐµÐºÐ°
            if (state.noiseSuppressionManager) {
              const processedStream = state.noiseSuppressionManager.getProcessedStream();
              const audioTrack = processedStream?.getAudioTracks()[0];
              if (audioTrack) {
                audioTrack.enabled = !state.isMuted;
              }
            }
            
            return true;
          }
          
          return false;
        } catch (error) {
          console.error('Error changing noise suppression mode:', error);
          return false;
        }
      },
      
      // Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð·Ð²Ð¾Ð½ÐºÐ°
      endCall: async () => {
        try {
          const state = get();
          
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹
          voiceCallApi.off('peerJoined');
          voiceCallApi.off('peerLeft');
          voiceCallApi.off('peerMuteStateChanged');
          voiceCallApi.off('peerAudioStateChanged');
          voiceCallApi.off('newProducer');
          voiceCallApi.off('producerClosed');
          voiceCallApi.off('globalAudioStateChanged');
          
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ socket Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸
          if (voiceCallApi.socket) {
            voiceCallApi.socket.off('globalAudioState');
          }
          
          if (state.localStream) {
            state.localStream.getTracks().forEach(track => track.stop());
          }
          
          // ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° ÑˆÑƒÐ¼Ð¾Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
          if (state.noiseSuppressionManager) {
            state.noiseSuppressionManager.cleanup();
          }
          
          // Ð—Ð°ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ audio context
          if (state.audioContext && state.audioContext.state !== 'closed') {
            await state.audioContext.close();
          }
          
          if (state.sendTransport) {
            state.sendTransport.close();
          }
          
          if (state.recvTransport) {
            state.recvTransport.close();
          }
          
          state.consumers.forEach(consumer => consumer.close());
          state.producers.forEach(producer => producer.close());
          
          // ÐžÑ‡Ð¸ÑÑ‚ÐºÐ° GainNodes Ð¸ audio elements
          state.gainNodes.forEach(gainNode => {
            try {
              gainNode.disconnect();
            } catch (e) {
              console.warn('Error disconnecting gain node:', e);
            }
          });
          
          state.audioElements.forEach(audioElement => {
            try {
              audioElement.pause();
              audioElement.srcObject = null;
              if (audioElement.parentNode) {
                audioElement.parentNode.removeChild(audioElement);
              }
            } catch (e) {
              console.warn('Error removing audio element:', e);
            }
          });
          
          await voiceCallApi.disconnect();
          
          set({
            isConnected: false,
            isInCall: false,
            currentRoomId: null,
            currentCall: null,
            participants: [],
            userVolumes: new Map(),
            userMutedStates: new Map(),
            showVolumeSliders: new Map(),
            gainNodes: new Map(),
            audioElements: new Map(),
            previousVolumes: new Map(),
            peerIdToUserIdMap: new Map(),
            device: null,
            sendTransport: null,
            recvTransport: null,
            producers: new Map(),
            consumers: new Map(),
            localStream: null,
            noiseSuppressionManager: null,
            audioContext: null,
            connecting: false
          });
          
          console.log('Call ended successfully');
        } catch (error) {
          console.error('Failed to end call:', error);
          set({ error: error.message });
        }
      },
      
      // Ð”ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ñ ÑÐºÑ€Ð°Ð½Ð°
      startScreenShare: async () => {
        try {
          const state = get();
          if (!state.sendTransport) {
            throw new Error('Transport not ready');
          }

          // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÑƒÑ‰ÐµÑÑ‚Ð²ÑƒÑŽÑ‰ÑƒÑŽ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸ÑŽ ÑÐºÑ€Ð°Ð½Ð°, ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
          if (state.isScreenSharing) {
            await get().stopScreenShare();
          }

          console.log('Requesting screen sharing access...');
          const stream = await navigator.mediaDevices.getDisplayMedia({
            video: {
              cursor: 'always',
              frameRate: { ideal: 60, max: 60 },
              width: { ideal: 1920, max: 1920 },
              height: { ideal: 1080, max: 1080 },
              aspectRatio: 16/9,
              displaySurface: 'monitor',
              resizeMode: 'crop-and-scale'
            },
            audio: {
              echoCancellation: true,
              noiseSuppression: true,
              autoGainControl: true,
              sampleRate: 48000,
              channelCount: 2,
              sampleSize: 16
            }
          });

          console.log('Screen sharing access granted');

          // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ¸ Ð¿Ð¾Ñ‚Ð¾ÐºÐ° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼
          stream.getVideoTracks()[0].onended = () => {
            console.log('Screen sharing stopped by user');
            get().stopScreenShare();
          };

          // Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº
          set({ screenShareStream: stream });

          const videoTrack = stream.getVideoTracks()[0];
          if (!videoTrack) {
            throw new Error('No video track available');
          }

          console.log('Creating screen sharing producer...');
          const videoProducer = await state.sendTransport.produce({
            track: videoTrack,
            encodings: [
              {
                scaleResolutionDownBy: 1,
                maxBitrate: 5000000, // 5 Mbps Ð´Ð»Ñ Full HD
                maxFramerate: 60
              }
            ],
            codecOptions: {
              videoGoogleStartBitrate: 3000, // ÐÐ°Ñ‡Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð¸Ñ‚Ñ€ÐµÐ¹Ñ‚ 3 Mbps
              videoGoogleMaxBitrate: 5000 // ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð±Ð¸Ñ‚Ñ€ÐµÐ¹Ñ‚ 5 Mbps
            },
            appData: {
              mediaType: 'screen',
              trackType: 'video',
              userId: state.currentUserId,
              userName: state.currentUserName,
              width: videoTrack.getSettings().width,
              height: videoTrack.getSettings().height,
              frameRate: videoTrack.getSettings().frameRate
            }
          });

          console.log('Screen sharing video producer created:', videoProducer.id);

          // Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ audio producer Ð´Ð»Ñ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐºÑ€Ð°Ð½Ð°
          const audioTrack = stream.getAudioTracks()[0];
          let audioProducer = null;
          
          if (audioTrack) {
            console.log('Creating screen sharing audio producer...');
            audioProducer = await state.sendTransport.produce({
              track: audioTrack,
              appData: {
                mediaType: 'screen',
                trackType: 'audio',
                userId: state.currentUserId,
                userName: state.currentUserName
              }
            });
            console.log('Screen sharing audio producer created:', audioProducer.id);
          } else {
            console.log('No audio track in screen share stream');
          }

          // Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ producers
          const newProducers = new Map(state.producers);
          newProducers.set('screen-video', videoProducer);
          if (audioProducer) {
            newProducers.set('screen-audio', audioProducer);
          }
          set({ 
            producers: newProducers,
            isScreenSharing: true 
          });

          // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ video producer
          videoProducer.on('transportclose', () => {
            console.log('Screen sharing video transport closed');
            get().stopScreenShare();
          });

          videoProducer.on('trackended', () => {
            console.log('Screen sharing track ended');
            get().stopScreenShare();
          });

        } catch (error) {
          console.error('Error starting screen share:', error);
          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð¿Ñ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ
          const currentState = get();
          if (currentState.screenShareStream) {
            currentState.screenShareStream.getTracks().forEach(track => track.stop());
          }
          set({ 
            screenShareStream: null,
            isScreenSharing: false,
            error: 'Failed to start screen sharing: ' + error.message 
          });
        }
      },

      stopScreenShare: async () => {
        console.log('Stopping screen sharing...');

        try {
          const state = get();
          // Ð£Ð²ÐµÐ´Ð¾Ð¼Ð»ÑÐµÐ¼ ÑÐµÑ€Ð²ÐµÑ€ Ð¾Ð± Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐµ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ð¸Ð¸ ÑÐºÑ€Ð°Ð½Ð°
          const videoProducer = state.producers.get('screen-video');
          
          if (videoProducer && voiceCallApi.socket) {
            try {
              await voiceCallApi.stopScreenSharing(videoProducer.id);
            } catch (error) {
              console.log('stopScreenShare: voiceCallApi.stopScreenSharing failed:', error.message);
              // ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÐµÐ½Ð¸Ðµ Ð´Ð°Ð¶Ðµ ÐµÑÐ»Ð¸ ÑÐµÑ€Ð²ÐµÑ€ Ð½Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð¸Ð»
            }
          }

          // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº
          if (state.screenShareStream) {
            state.screenShareStream.getTracks().forEach(track => track.stop());
          }

          // Ð£Ð´Ð°Ð»ÑÐµÐ¼ producers
          const newProducers = new Map(state.producers);
          newProducers.delete('screen-video');
          newProducers.delete('screen-audio');

          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ screen share audio elements
          const newAudioElements = new Map(state.audioElements);
          for (const [key, audioElement] of newAudioElements.entries()) {
            if (key.startsWith('screen-share-audio-')) {
              try {
                audioElement.pause();
                audioElement.srcObject = null;
                if (audioElement.parentNode) {
                  audioElement.parentNode.removeChild(audioElement);
                }
                newAudioElements.delete(key);
                console.log('Removed screen share audio element:', key);
              } catch (e) {
                console.warn('Error removing screen share audio element:', e);
              }
            }
          }

          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
          set({
            screenShareStream: null,
            isScreenSharing: false,
            producers: newProducers,
            audioElements: newAudioElements
          });

          console.log('Screen sharing stopped successfully');
        } catch (error) {
          console.error('Error stopping screen share:', error);
          set({ error: 'Failed to stop screen sharing: ' + error.message });
        }
      },

      toggleScreenShare: async () => {
        console.log('toggleScreenShare called');
        const state = get();
        console.log('Current state:', { isScreenSharing: state.isScreenSharing, sendTransport: !!state.sendTransport });
        if (state.isScreenSharing) {
          console.log('Stopping screen share...');
          await get().stopScreenShare();
          console.log('After stopScreenShare, state:', { 
            isScreenSharing: get().isScreenSharing, 
            screenShareStream: get().screenShareStream 
          });
        } else {
          console.log('Starting screen share...');
          await get().startScreenShare();
        }
      },

      // Ð’ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ/Ð²Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
      toggleVideo: async () => {
        console.log('ðŸŽ¥ðŸŽ¥ðŸŽ¥ toggleVideo called in callStore');
        const state = get();
        console.log('ðŸŽ¥ Current state:', { isVideoEnabled: state.isVideoEnabled, sendTransport: !!state.sendTransport });
        if (state.isVideoEnabled) {
          console.log('ðŸŽ¥ Stopping video...');
          await get().stopVideo();
        } else {
          console.log('ðŸŽ¥ Starting video...');
          await get().startVideo();
        }
      },

      // Ð’ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
      startVideo: async () => {
        console.log('ðŸŽ¥ðŸŽ¥ðŸŽ¥ startVideo called');
        try {
          const state = get();
          console.log('ðŸŽ¥ startVideo state check:', { sendTransport: !!state.sendTransport, currentUserId: state.currentUserId });
          if (!state.sendTransport) {
            throw new Error('Send transport not available');
          }

          console.log('Requesting camera access...');
          const cameraStream = await navigator.mediaDevices.getUserMedia({
            video: {
              width: { ideal: 1280, max: 1920 },
              height: { ideal: 720, max: 1080 },
              frameRate: { ideal: 30, max: 60 },
              facingMode: 'user'
            },
            audio: false // Ð¯Ð²Ð½Ð¾ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð»Ñ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
          });

          console.log('Camera access granted');
          set({ cameraStream: cameraStream, isVideoEnabled: true });

          const videoTrack = cameraStream.getVideoTracks()[0];
          if (!videoTrack) {
            throw new Error('No video track available');
          }

          console.log('Creating video producer...');
          const videoProducer = await state.sendTransport.produce({
            track: videoTrack,
            encodings: [
              {
                scaleResolutionDownBy: 1,
                maxBitrate: 2500000, // 2.5 Mbps Ð´Ð»Ñ HD
                maxFramerate: 30
              }
            ],
            codecOptions: {
              videoGoogleStartBitrate: 1500,
              videoGoogleMaxBitrate: 2500
            },
            appData: {
              mediaType: 'camera',
              trackType: 'video',
              userId: state.currentUserId,
              userName: state.currentUserName
            }
          });

          console.log('Video producer created:', videoProducer.id);
          set({ videoProducer });

          // ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹ video producer
          videoProducer.on('transportclose', () => {
            console.log('Video transport closed');
            get().stopVideo();
          });

          videoProducer.on('trackended', () => {
            console.log('Video track ended');
            get().stopVideo();
          });

        } catch (error) {
          console.error('Error starting video:', error);
          set({ error: 'Failed to start video: ' + error.message });
        }
      },

      // Ð’Ñ‹ÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
      stopVideo: async () => {
        console.log('ðŸŽ¥ðŸŽ¥ðŸŽ¥ STOP VIDEO START ðŸŽ¥ðŸŽ¥ðŸŽ¥');
        try {
          const state = get();
          console.log('ðŸŽ¥ Current state before stop:', {
            isVideoEnabled: state.isVideoEnabled,
            hasVideoProducer: !!state.videoProducer,
            hasCameraStream: !!state.cameraStream,
            hasAudioStream: !!state.audioStream,
            hasLocalStream: !!state.localStream,
            producersCount: state.producers.size,
            producersKeys: Array.from(state.producers.keys())
          });
          
          // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ video producer
          if (state.videoProducer) {
            try {
              console.log('ðŸŽ¥ Closing video producer:', state.videoProducer.id);
              console.log('ðŸŽ¥ Sending stopVideo event to server:', {
                producerId: state.videoProducer.id
              });
              
              // ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ðµ Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€
              await voiceCallApi.stopVideo(state.videoProducer.id);
              
              await state.videoProducer.close();
              console.log('ðŸŽ¥ Video producer closed successfully');
            } catch (error) {
              console.log('ðŸŽ¥ stopVideo: videoProducer.close failed:', error.message);
            }
          } else {
            console.log('ðŸŽ¥ No video producer to close');
          }

          // ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹ (Ð¾Ð½ ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ð¸Ð´ÐµÐ¾ Ñ‚Ñ€ÐµÐºÐ¸)
          if (state.cameraStream) {
            console.log('ðŸŽ¥ Stopping camera stream tracks');
            const tracks = state.cameraStream.getTracks();
            console.log('ðŸŽ¥ Camera stream tracks count:', tracks.length);
            tracks.forEach(track => {
              console.log('ðŸŽ¥ Stopping camera track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled);
              track.stop();
            });
            console.log('ðŸŽ¥ Camera stream tracks stopped');
          } else {
            console.log('ðŸŽ¥ No camera stream to stop');
          }

          // ÐžÑ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ Ð²ÐµÐ±ÐºÐ°Ð¼ÐµÑ€Ñ‹
          console.log('ðŸŽ¥ Clearing video state...');
          set({
            isVideoEnabled: false,
            videoProducer: null,
            cameraStream: null
          });
          console.log('ðŸŽ¥ Video state cleared');
          
          console.log('ðŸŽ¥ Video stopped, but audio should continue working');
          
          // ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¿ÐµÑ€ÐµÐ¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ audio consumers Ðº audio producers
          const audioConsumers = Array.from(get().consumers.values()).filter(c => c.kind === 'audio');
          audioConsumers.forEach(consumer => {
            if (!consumer.closed) {
              console.log('ðŸŽ¥ Reconnecting audio consumer:', consumer.id);
              // ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð²Ð¾Ð·Ð¾Ð±Ð½Ð¾Ð²Ð»ÑÐµÐ¼ consumer
              if (consumer.paused) {
                consumer.resume();
              }
              // ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð¿ÐµÑ€ÐµÐ¿Ð¾Ð´ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ðº producer
              if (consumer.producer && consumer.producer.paused) {
                consumer.producer.resume();
              }
            }
          });
          
          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, Ñ‡Ñ‚Ð¾ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¹ Ð°ÑƒÐ´Ð¸Ð¾ producer Ð½Ðµ Ð·Ð°Ñ‚Ñ€Ð¾Ð½ÑƒÑ‚
          const currentState = get();
          console.log('ðŸŽ¥ Final state after stop:', {
            isVideoEnabled: currentState.isVideoEnabled,
            hasVideoProducer: !!currentState.videoProducer,
            hasCameraStream: !!currentState.cameraStream,
            hasAudioStream: !!currentState.audioStream,
            hasLocalStream: !!currentState.localStream,
            producersCount: currentState.producers.size,
            producersKeys: Array.from(currentState.producers.keys())
          });
          
          console.log('ðŸŽ¥ Remaining producers after video stop:', Array.from(currentState.producers.keys()));
          console.log('ðŸŽ¥ Audio context state:', currentState.audioContext?.state);
          console.log('ðŸŽ¥ Camera stream state:', currentState.cameraStream ? 'exists' : 'null');
          console.log('ðŸŽ¥ Is video enabled:', currentState.isVideoEnabled);
          
          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð°ÐºÑ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð°ÑƒÐ´Ð¸Ð¾ Ñ‚Ñ€ÐµÐºÐ¸ Ð² Ð¾ÑÐ½Ð¾Ð²Ð½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ
          if (currentState.audioStream) {
            const audioTracks = currentState.audioStream.getAudioTracks();
            console.log('ðŸŽ¥ Main audio stream tracks:', audioTracks.length);
            audioTracks.forEach(track => {
              console.log('ðŸŽ¥ Main audio track:', track.label, 'enabled:', track.enabled, 'readyState:', track.readyState);
            });
          } else {
            console.log('ðŸŽ¥ Main audio stream: null');
          }

          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ localStream
          if (currentState.localStream) {
            const localTracks = currentState.localStream.getTracks();
            console.log('ðŸŽ¥ Local stream tracks:', localTracks.length);
            localTracks.forEach(track => {
              console.log('ðŸŽ¥ Local track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled, 'readyState:', track.readyState);
            });
          } else {
            console.log('ðŸŽ¥ Local stream: null');
          }

          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ consumers
          const finalState = get();
          console.log('ðŸŽ¥ Consumers after video stop:', Array.from(finalState.consumers.keys()));
          console.log('ðŸŽ¥ Consumers count:', finalState.consumers.size);
          finalState.consumers.forEach((consumer, id) => {
            console.log('ðŸŽ¥ Consumer:', id, 'kind:', consumer.kind, 'paused:', consumer.paused, 'producerPaused:', consumer.producerPaused, 'closed:', consumer.closed);
            console.log('ðŸŽ¥ Consumer producer:', consumer.producerId, 'producer closed:', consumer.producer?.closed, 'producer paused:', consumer.producer?.paused);
          });

          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ producers
          console.log('ðŸŽ¥ Producers after video stop:', Array.from(finalState.producers.keys()));
          console.log('ðŸŽ¥ Producers count:', finalState.producers.size);
          finalState.producers.forEach((producer, id) => {
            console.log('ðŸŽ¥ Producer:', id, 'kind:', producer.kind, 'paused:', producer.paused, 'closed:', producer.closed);
          });

          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ audio elements
          console.log('ðŸŽ¥ Audio elements count:', finalState.audioElements.size);
          finalState.audioElements.forEach((audioElement, userId) => {
            console.log('ðŸŽ¥ Audio element for user:', userId, 'srcObject:', !!audioElement.srcObject, 'paused:', audioElement.paused, 'muted:', audioElement.muted, 'currentTime:', audioElement.currentTime, 'duration:', audioElement.duration);
            if (audioElement.srcObject) {
              console.log('ðŸŽ¥ Audio element srcObject tracks:', audioElement.srcObject.getTracks().length);
              audioElement.srcObject.getTracks().forEach(track => {
                console.log('ðŸŽ¥ Audio track:', track.label, 'kind:', track.kind, 'enabled:', track.enabled, 'readyState:', track.readyState);
              });
            }
          });

          // ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ gain nodes
          console.log('ðŸŽ¥ Gain nodes count:', finalState.gainNodes.size);
          finalState.gainNodes.forEach((gainNode, userId) => {
            console.log('ðŸŽ¥ Gain node for user:', userId, 'gain:', gainNode.gain.value, 'context:', gainNode.context.state);
          });

          console.log('ðŸŽ¥ðŸŽ¥ðŸŽ¥ STOP VIDEO END ðŸŽ¥ðŸŽ¥ðŸŽ¥');
          console.log('Video stopped successfully');
        } catch (error) {
          console.error('Error stopping video:', error);
          set({ error: 'Failed to stop video: ' + error.message });
        }
      }
    }),
    {
      name: 'call-store',
    }
  )
);
